{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProgettoVisione.pynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ftrunfio/progettoVisione/blob/master/ProgettoVisione_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbx_MHpoNTk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "aaf96964-99f2-4441-feac-0366be1a72c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrSO-8RMNXmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a991b4bd-e66a-44d6-9882-3a46da788703"
      },
      "source": [
        "cd drive/My Drive/Colab Notebooks/Progetto"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Progetto\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wblBwgZNNiKR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d0daca30-5396-4b35-a273-92c86b890061"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 28512, done.\u001b[K\n",
            "remote: Total 28512 (delta 0), reused 0 (delta 0), pack-reused 28512\u001b[K\n",
            "Receiving objects: 100% (28512/28512), 509.52 MiB | 13.94 MiB/s, done.\n",
            "Resolving deltas: 100% (17625/17625), done.\n",
            "Checking out files: 100% (3037/3037), done.\n",
            "Cloning into 'tensorflow_object_detection_tutorial'...\n",
            "remote: Enumerating objects: 877, done.\u001b[K\n",
            "remote: Total 877 (delta 0), reused 0 (delta 0), pack-reused 877\u001b[K\n",
            "Receiving objects: 100% (877/877), 63.91 MiB | 15.08 MiB/s, done.\n",
            "Resolving deltas: 100% (422/422), done.\n",
            "Checking out files: 100% (857/857), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puiZDgFdNrvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y -qq protobuf-compiler python-pil python-lxml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xZPFzknPI7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('models/research')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv5T-VjsPN1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "b815594c-108c-43b5-91ce-3f303e58097c"
      },
      "source": [
        "ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34ma3c_blogpost\u001b[0m/                      \u001b[01;34mlm_commonsense\u001b[0m/\n",
            "\u001b[01;34madversarial_crypto\u001b[0m/                \u001b[01;34mlstm_object_detection\u001b[0m/\n",
            "\u001b[01;34madversarial_logit_pairing\u001b[0m/         \u001b[01;34mmarco\u001b[0m/\n",
            "\u001b[01;34madversarial_text\u001b[0m/                  \u001b[01;34mmaskgan\u001b[0m/\n",
            "\u001b[01;34madv_imagenet_models\u001b[0m/               \u001b[01;34mminigo\u001b[0m/\n",
            "\u001b[01;34mastronet\u001b[0m/                          \u001b[01;34mmorph_net\u001b[0m/\n",
            "\u001b[01;34mattention_ocr\u001b[0m/                     \u001b[01;34mnamignizer\u001b[0m/\n",
            "\u001b[01;34maudioset\u001b[0m/                          \u001b[01;34mneural_gpu\u001b[0m/\n",
            "\u001b[01;34mautoaugment\u001b[0m/                       \u001b[01;34mneural_programmer\u001b[0m/\n",
            "\u001b[01;34mautoencoder\u001b[0m/                       \u001b[01;34mnext_frame_prediction\u001b[0m/\n",
            "\u001b[01;34mbrain_coder\u001b[0m/                       \u001b[01;34mnst_blogpost\u001b[0m/\n",
            "\u001b[01;34mcognitive_mapping_and_planning\u001b[0m/    \u001b[01;34mobject_detection\u001b[0m/\n",
            "\u001b[01;34mcognitive_planning\u001b[0m/                \u001b[01;34mpcl_rl\u001b[0m/\n",
            "\u001b[01;34mcompression\u001b[0m/                       \u001b[01;34mptn\u001b[0m/\n",
            "\u001b[01;34mcvt_text\u001b[0m/                          \u001b[01;34mqa_kg\u001b[0m/\n",
            "\u001b[01;34mdeep_contextual_bandits\u001b[0m/           README.md\n",
            "\u001b[01;34mdeeplab\u001b[0m/                           \u001b[01;34mreal_nvp\u001b[0m/\n",
            "\u001b[01;34mdeep_speech\u001b[0m/                       \u001b[01;34mrebar\u001b[0m/\n",
            "\u001b[01;34mdelf\u001b[0m/                              \u001b[01;34mresnet\u001b[0m/\n",
            "\u001b[01;34mdifferential_privacy\u001b[0m/              \u001b[01;34msentiment_analysis\u001b[0m/\n",
            "\u001b[01;34mdomain_adaptation\u001b[0m/                 \u001b[01;34mseq2species\u001b[0m/\n",
            "\u001b[01;34mefficient-hrl\u001b[0m/                     setup.py\n",
            "\u001b[01;34mfeelvos\u001b[0m/                           \u001b[01;34mskip_thoughts\u001b[0m/\n",
            "\u001b[01;34mfivo\u001b[0m/                              \u001b[01;34mslim\u001b[0m/\n",
            "\u001b[01;34mgan\u001b[0m/                               \u001b[01;34msteve\u001b[0m/\n",
            "\u001b[01;34mglobal_objectives\u001b[0m/                 \u001b[01;34mstreet\u001b[0m/\n",
            "\u001b[01;34mim2txt\u001b[0m/                            \u001b[01;34mstruct2depth\u001b[0m/\n",
            "\u001b[01;34minception\u001b[0m/                         \u001b[01;34mswivel\u001b[0m/\n",
            "\u001b[01;34mkeypointnet\u001b[0m/                       \u001b[01;34msyntaxnet\u001b[0m/\n",
            "\u001b[01;34mlearned_optimizer\u001b[0m/                 \u001b[01;34mtcn\u001b[0m/\n",
            "\u001b[01;34mlearning_to_remember_rare_events\u001b[0m/  \u001b[01;34mtensorrt\u001b[0m/\n",
            "\u001b[01;34mlearning_unsupervised_learning\u001b[0m/    \u001b[01;34mtextsum\u001b[0m/\n",
            "\u001b[01;34mlexnet_nc\u001b[0m/                         \u001b[01;34mtransformer\u001b[0m/\n",
            "\u001b[01;34mlfads\u001b[0m/                             \u001b[01;34mvid2depth\u001b[0m/\n",
            "\u001b[01;34mlm_1b\u001b[0m/                             \u001b[01;34mvideo_prediction\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chBlXmdSPSnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLuT7sxiPmf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/Progetto/models')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dxeG7olPv0h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "59ec8084-f29b-4a9f-fd1e-d3729b6e615b"
      },
      "source": [
        "%run object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running tests under Python 3.6.8: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTest.test_session\n",
            "[  SKIPPED ] ModelBuilderTest.test_session\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 16 tests in 0.160s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-31812fc4de3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run object_detection/builders/model_builder_test.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-58>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    740\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                         \u001b[0;31m# regular execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m                         \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'i'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    726\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                             runner(filename, prog_ns, prog_ns,\n\u001b[0;32m--> 728\u001b[0;31m                                     exit_ignore=exit_ignore)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m't'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mmpl_execfile\u001b[0;34m(fname, *where, **kw)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# make rendering call now, if the user tried to do it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_if_interactive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_if_interactive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'called'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVUvL4KWQQaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2110eeb7-e070-4ffb-eb3f-33ba54907b72"
      },
      "source": [
        "cd object_detection"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpWQi6HpQVee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "e96909e8-2c86-481e-c9f5-939631d497e8"
      },
      "source": [
        "!python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 08:59:12.581902 140466756159360 deprecation_wrapper.py:119] From generate_tfrecord.py:102: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0718 08:59:12.582894 140466756159360 deprecation_wrapper.py:119] From generate_tfrecord.py:88: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0718 08:59:12.773432 140466756159360 deprecation_wrapper.py:119] From generate_tfrecord.py:47: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/train.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGyfIBUVTR2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2e049471-0c3d-4845-cac5-6ae66610a7a3"
      },
      "source": [
        "!python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 08:59:53.967347 140003249166208 deprecation_wrapper.py:119] From generate_tfrecord.py:102: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0718 08:59:53.968026 140003249166208 deprecation_wrapper.py:119] From generate_tfrecord.py:88: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0718 08:59:54.028266 140003249166208 deprecation_wrapper.py:119] From generate_tfrecord.py:47: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0bUbADSVHFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d8c45fb5-05b6-495e-b6a2-8d507c8c37af"
      },
      "source": [
        "!python legacy/train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_coco.config"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 09:11:32.831504 140280725968768 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0718 09:11:33.399707 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0718 09:11:33.508495 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "W0718 09:11:33.586804 140280725968768 deprecation_wrapper.py:119] From legacy/train.py:55: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0718 09:11:33.587045 140280725968768 deprecation_wrapper.py:119] From legacy/train.py:55: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0718 09:11:33.587648 140280725968768 deprecation_wrapper.py:119] From legacy/train.py:184: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0718 09:11:33.588211 140280725968768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/absl/app.py:251: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "W0718 09:11:33.588400 140280725968768 deprecation_wrapper.py:119] From legacy/train.py:90: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0718 09:11:33.588897 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0718 09:11:33.595029 140280725968768 deprecation_wrapper.py:119] From legacy/train.py:95: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
            "\n",
            "W0718 09:11:33.604817 140280725968768 deprecation.py:323] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/legacy/trainer.py:266: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.create_global_step\n",
            "W0718 09:11:33.609862 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0718 09:11:33.610087 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W0718 09:11:33.631273 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0718 09:11:33.633980 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W0718 09:11:33.634106 140280725968768 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
            "W0718 09:11:33.641776 140280725968768 deprecation.py:323] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0718 09:11:33.641963 140280725968768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0718 09:11:33.671812 140280725968768 deprecation.py:323] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0718 09:11:33.909046 140280725968768 deprecation.py:323] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "W0718 09:11:33.917731 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0718 09:11:33.924246 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/core/preprocessor.py:626: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0718 09:11:33.992573 140280725968768 deprecation.py:323] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/core/preprocessor.py:196: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0718 09:11:34.007170 140280725968768 deprecation.py:323] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/core/box_list_ops.py:206: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0718 09:11:35.060678 140280725968768 deprecation.py:323] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "W0718 09:11:35.065551 140280725968768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:753: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0718 09:11:35.066861 140280725968768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:753: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0718 09:11:35.078237 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0718 09:11:35.527498 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/core/preprocessor.py:2660: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0718 09:11:40.083975 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0718 09:11:40.084236 140280725968768 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0718 09:11:40.129620 140280725968768 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0718 09:11:40.175154 140280725968768 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0718 09:11:40.220219 140280725968768 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0718 09:11:40.267351 140280725968768 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0718 09:11:40.313223 140280725968768 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "W0718 09:11:42.922616 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "W0718 09:11:42.924316 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "W0718 09:11:43.335582 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/legacy/trainer.py:208: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
            "\n",
            "W0718 09:11:43.336542 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/builders/optimizer_builder.py:95: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0718 09:11:43.336831 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "W0718 09:11:43.350093 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "W0718 09:11:45.818702 140280725968768 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0718 09:11:48.320286 140280725968768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0718 09:11:54.300842 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/legacy/trainer.py:353: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "W0718 09:11:54.732746 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/legacy/trainer.py:355: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.\n",
            "\n",
            "W0718 09:11:54.735492 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/legacy/trainer.py:359: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\n",
            "\n",
            "W0718 09:11:54.740052 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/legacy/trainer.py:368: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "W0718 09:11:54.750937 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/legacy/trainer.py:376: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0718 09:11:55.761194 140280725968768 deprecation_wrapper.py:119] From /content/drive/My Drive/Colab Notebooks/Progetto/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0718 09:11:56.083710 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.083940 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.084046 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.084152 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.084244 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.084354 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.084486 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.084578 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.084687 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.084788 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.084891 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.085024 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.085118 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.085204 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.085291 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.085395 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.085501 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.085590 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/Conv_1/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.085700 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.085793 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.085894 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.086000 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.086100 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.086197 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.086295 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.086381 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.086478 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.086583 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.086700 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.086788 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.086881 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.086969 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.087098 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.087216 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.087305 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.087390 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.087492 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.087579 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.087680 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.087778 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.087865 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.087978 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.088108 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.088196 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.088281 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.088375 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.088470 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.088557 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.088649 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.088756 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.088841 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.088958 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.089043 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.089126 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.089231 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.089313 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.089394 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.089521 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.089607 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.089705 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.089811 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.089899 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.089987 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.090081 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.090169 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.090286 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.090438 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.090541 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.090628 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.090751 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.090840 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.090941 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.091067 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.091155 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.091240 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.091333 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.091440 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.091528 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.091635 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.091745 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.091848 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.091941 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.092028 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.092112 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.092203 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.092288 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.117155 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.117754 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.117894 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.118039 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.118316 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.118455 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.118584 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.118878 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.119039 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.119167 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.119480 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.119615 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.119967 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.120146 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.120286 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.120573 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.120735 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.121025 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.121162 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.121327 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.121601 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.121758 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.122057 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.122192 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.122335 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.122618 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.122769 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.123056 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.123210 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.123475 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.123612 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.123777 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.124070 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.124202 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.124506 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.124643 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.124793 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.125132 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.125292 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.125597 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.125766 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.125892 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.126214 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.126462 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.126745 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.126912 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.127082 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.127395 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.127523 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.127879 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.128028 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.128289 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.128436 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.128565 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.128868 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.129035 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.129272 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.129505 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.129645 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.129956 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.130084 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.130365 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.130503 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.130629 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.130963 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.131124 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.131420 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.131567 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.131727 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.132066 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.132204 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.132515 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.132647 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.132969 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.133114 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.133240 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.133558 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.133711 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.133977 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.134123 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.134250 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.134529 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.134705 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.135056 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.135199 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.135335 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.135626 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.135781 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.135971 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.136243 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.136389 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.136704 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.136838 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.137154 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.137334 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.137640 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.137800 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.137965 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.138293 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.138420 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.138740 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.138880 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.139168 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.139348 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.139543 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.139847 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.140000 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.140286 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.140425 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.140591 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.140881 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.141021 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.141304 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.141441 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.141566 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.141886 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.142027 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.142340 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.142494 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.142773 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.142911 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.143059 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.143347 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.143476 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.143761 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.143898 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.144034 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.144338 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.144471 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.144775 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.144933 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.145192 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.145329 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.145465 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.145761 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.145894 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.146186 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.146324 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.146450 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.146754 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.146889 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.147178 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.147327 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.147452 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.147752 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.147913 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.148204 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.148338 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.148472 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.148777 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.148908 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.149307 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.149454 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.149580 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.149909 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.150051 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.150333 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.150480 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.150769 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.150912 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.151059 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.151350 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.151498 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.151728 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.151863 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.152018 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.152134 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.152239 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.152352 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.152489 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.152612 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.152755 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.152970 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.153106 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.153224 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.153366 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.153511 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.153629 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.153779 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.153899 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.154018 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.154154 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.154275 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.154393 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.154532 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.154649 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.154790 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.154917 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.155034 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.155150 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.155288 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.155406 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.155533 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.155679 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.155801 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.155919 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.156047 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.156167 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.156282 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.156432 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.156566 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.156710 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.156846 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.156968 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.157087 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.157215 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.157335 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.157466 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.157607 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.157749 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.157867 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.157996 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.158116 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.158232 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.158356 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.158487 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.158604 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.158765 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.158884 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.159014 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.159159 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.159278 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.159393 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.159529 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.159646 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.159786 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.159924 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.160044 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.160175 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.160342 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.160501 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.160618 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.160765 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.160913 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.161088 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.161226 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.161346 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.161475 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.161602 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.161743 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.161891 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.162060 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.162193 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.162307 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.162458 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.162580 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.162715 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.162844 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.162961 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.163140 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.163279 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.163448 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.163565 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.163722 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.163942 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.164082 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.164237 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.164355 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.164483 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.164609 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.164753 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.164871 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.165021 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.165150 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.165295 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.165436 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.165555 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.165692 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.165822 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.165940 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.166059 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.166197 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.166316 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.166442 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.166570 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.166705 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.166826 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.166952 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.167069 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.167184 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.167320 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.167448 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.167566 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.167711 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.167830 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.167948 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.168075 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.168191 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.168305 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.168456 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.168574 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.168707 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.168836 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.168956 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.169073 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.169198 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.169314 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.169440 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.169577 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.169712 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.169830 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.169957 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.170078 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.170193 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.170319 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.170446 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.170564 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.170720 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.170842 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.170958 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.171084 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.171203 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.171317 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.171463 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.171582 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.171716 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.171856 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.171976 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.172093 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.172221 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.172340 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.172467 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.172591 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.172730 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.172846 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.172978 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.173097 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.173213 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.173338 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.173466 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.173583 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.173728 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.173848 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.173964 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.174102 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.174223 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.174341 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.174503 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.174627 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.174772 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.174902 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.175024 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.175185 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.175338 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.175471 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.175590 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.175738 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.175858 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.175976 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.176109 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.176226 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.176343 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.176492 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.176612 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.176753 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.176880 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.177000 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.177129 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.177283 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.177426 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.177544 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.177702 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.177831 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.177948 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.178111 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.178229 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.178345 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.178480 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.178598 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.178738 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.178879 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.178999 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.179114 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.179240 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.179358 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.179498 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.179624 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.179765 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.179883 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.180019 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.180140 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.180296 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.180505 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.180623 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.180764 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.180957 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.181107 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.181237 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.181458 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.181578 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.181708 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.181839 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.181972 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.182104 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.182228 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.182344 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.182470 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.182609 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.182751 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.182899 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.183041 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.183171 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.183288 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.183423 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.183543 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.183658 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.183822 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.183943 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.184060 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.184186 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.184303 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.184430 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.184556 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.184695 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.184828 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.184967 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.185079 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.185224 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.185349 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.185477 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.185592 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.185735 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.185853 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.185968 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.186139 140280725968768 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.\n",
            "W0718 09:11:56.186263 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.186381 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.186511 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.186640 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.186781 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.186899 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.187024 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.187141 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.187288 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.187437 140280725968768 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0718 09:11:56.187558 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.187696 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.187814 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.187942 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.188060 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.188177 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.188303 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.188430 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.188547 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.188710 140280725968768 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0718 09:11:56.188846 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.188980 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.189167 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.189318 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.189468 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.189584 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.189724 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.189844 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.189960 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:56.190099 140280725968768 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.\n",
            "W0718 09:11:56.190233 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0718 09:11:56.190391 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights/RMSProp] is not available in checkpoint\n",
            "W0718 09:11:56.190577 140280725968768 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights/RMSProp_1] is not available in checkpoint\n",
            "W0718 09:11:57.338770 140280725968768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "2019-07-18 09:11:58.724899: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-07-18 09:11:58.726997: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12d299c0 executing computations on platform Host. Devices:\n",
            "2019-07-18 09:11:58.727035: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-07-18 09:11:58.733489: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-07-18 09:11:58.877159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-18 09:11:58.877803: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12d29d40 executing computations on platform CUDA. Devices:\n",
            "2019-07-18 09:11:58.877840: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-07-18 09:11:58.878094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-18 09:11:58.878467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-18 09:11:58.896645: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-18 09:11:59.063836: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-18 09:11:59.138391: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-18 09:11:59.161976: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-18 09:11:59.344613: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-18 09:11:59.451588: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-18 09:11:59.791120: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-18 09:11:59.791408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-18 09:11:59.791989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-18 09:11:59.792356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-18 09:11:59.796438: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-18 09:11:59.798649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-18 09:11:59.798701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-18 09:11:59.798720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-18 09:11:59.800799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-18 09:11:59.801347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-18 09:11:59.801746: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-07-18 09:11:59.801804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2019-07-18 09:12:03.074904: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "W0718 09:12:03.477872 140280725968768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0718 09:12:03.480301 140280725968768 saver.py:1280] Restoring parameters from ssd_mobilenet_v2_coco_2018_03_29/model.ckpt\n",
            "I0718 09:12:05.212565 140280725968768 session_manager.py:500] Running local_init_op.\n",
            "I0718 09:12:05.682294 140280725968768 session_manager.py:502] Done running local_init_op.\n",
            "I0718 09:12:17.078346 140280725968768 learning.py:754] Starting Session.\n",
            "I0718 09:12:17.404862 140279019214592 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n",
            "I0718 09:12:17.409024 140280725968768 learning.py:768] Starting Queues.\n",
            "I0718 09:12:27.849329 140279010821888 supervisor.py:1099] global_step/sec: 0\n",
            "2019-07-18 09:12:30.772047: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "I0718 09:12:35.346230 140277976831744 supervisor.py:1050] Recording summary at step 0.\n",
            "I0718 09:12:36.913355 140280725968768 learning.py:507] global step 1: loss = 14.7658 (18.972 sec/step)\n",
            "I0718 09:12:38.572497 140280725968768 learning.py:507] global step 2: loss = 14.1852 (1.086 sec/step)\n",
            "I0718 09:12:39.253273 140280725968768 learning.py:507] global step 3: loss = 13.8251 (0.679 sec/step)\n",
            "I0718 09:12:39.920493 140280725968768 learning.py:507] global step 4: loss = 13.0685 (0.665 sec/step)\n",
            "I0718 09:12:40.602908 140280725968768 learning.py:507] global step 5: loss = 12.9433 (0.681 sec/step)\n",
            "I0718 09:12:41.290908 140280725968768 learning.py:507] global step 6: loss = 12.4437 (0.686 sec/step)\n",
            "I0718 09:12:41.946452 140280725968768 learning.py:507] global step 7: loss = 12.2776 (0.654 sec/step)\n",
            "I0718 09:12:42.641163 140280725968768 learning.py:507] global step 8: loss = 12.0291 (0.693 sec/step)\n",
            "I0718 09:12:43.328448 140280725968768 learning.py:507] global step 9: loss = 11.7772 (0.685 sec/step)\n",
            "I0718 09:12:44.005622 140280725968768 learning.py:507] global step 10: loss = 11.4288 (0.675 sec/step)\n",
            "I0718 09:12:44.667827 140280725968768 learning.py:507] global step 11: loss = 11.1359 (0.660 sec/step)\n",
            "I0718 09:12:45.376141 140280725968768 learning.py:507] global step 12: loss = 11.0534 (0.707 sec/step)\n",
            "I0718 09:12:46.041715 140280725968768 learning.py:507] global step 13: loss = 11.1487 (0.664 sec/step)\n",
            "I0718 09:12:46.744578 140280725968768 learning.py:507] global step 14: loss = 10.8481 (0.701 sec/step)\n",
            "I0718 09:12:47.461584 140280725968768 learning.py:507] global step 15: loss = 10.4395 (0.715 sec/step)\n",
            "I0718 09:12:48.116400 140280725968768 learning.py:507] global step 16: loss = 10.3522 (0.653 sec/step)\n",
            "I0718 09:12:48.789420 140280725968768 learning.py:507] global step 17: loss = 10.0991 (0.671 sec/step)\n",
            "I0718 09:12:49.485540 140280725968768 learning.py:507] global step 18: loss = 10.1642 (0.694 sec/step)\n",
            "I0718 09:12:50.119908 140280725968768 learning.py:507] global step 19: loss = 10.0274 (0.633 sec/step)\n",
            "I0718 09:12:50.806804 140280725968768 learning.py:507] global step 20: loss = 9.6873 (0.685 sec/step)\n",
            "I0718 09:12:51.481413 140280725968768 learning.py:507] global step 21: loss = 9.4878 (0.673 sec/step)\n",
            "I0718 09:12:52.152982 140280725968768 learning.py:507] global step 22: loss = 9.5388 (0.670 sec/step)\n",
            "I0718 09:12:52.820768 140280725968768 learning.py:507] global step 23: loss = 9.3746 (0.666 sec/step)\n",
            "I0718 09:12:53.489034 140280725968768 learning.py:507] global step 24: loss = 9.0284 (0.666 sec/step)\n",
            "I0718 09:12:54.142087 140280725968768 learning.py:507] global step 25: loss = 9.1297 (0.651 sec/step)\n",
            "I0718 09:12:54.826748 140280725968768 learning.py:507] global step 26: loss = 9.0952 (0.683 sec/step)\n",
            "I0718 09:12:55.496072 140280725968768 learning.py:507] global step 27: loss = 9.0167 (0.667 sec/step)\n",
            "I0718 09:12:56.206786 140280725968768 learning.py:507] global step 28: loss = 9.3506 (0.709 sec/step)\n",
            "I0718 09:12:56.889157 140280725968768 learning.py:507] global step 29: loss = 8.6350 (0.681 sec/step)\n",
            "I0718 09:12:57.558389 140280725968768 learning.py:507] global step 30: loss = 8.7003 (0.667 sec/step)\n",
            "I0718 09:12:58.253715 140280725968768 learning.py:507] global step 31: loss = 7.9559 (0.693 sec/step)\n",
            "I0718 09:12:58.938956 140280725968768 learning.py:507] global step 32: loss = 8.8814 (0.684 sec/step)\n",
            "I0718 09:12:59.600589 140280725968768 learning.py:507] global step 33: loss = 8.2507 (0.660 sec/step)\n",
            "I0718 09:13:00.298480 140280725968768 learning.py:507] global step 34: loss = 8.1378 (0.696 sec/step)\n",
            "I0718 09:13:01.010506 140280725968768 learning.py:507] global step 35: loss = 8.0855 (0.710 sec/step)\n",
            "I0718 09:13:01.694593 140280725968768 learning.py:507] global step 36: loss = 8.4218 (0.682 sec/step)\n",
            "I0718 09:13:02.395984 140280725968768 learning.py:507] global step 37: loss = 8.2081 (0.699 sec/step)\n",
            "I0718 09:13:03.079417 140280725968768 learning.py:507] global step 38: loss = 8.2617 (0.680 sec/step)\n",
            "I0718 09:13:03.744051 140280725968768 learning.py:507] global step 39: loss = 8.2029 (0.663 sec/step)\n",
            "I0718 09:13:04.400156 140280725968768 learning.py:507] global step 40: loss = 7.9087 (0.654 sec/step)\n",
            "I0718 09:13:05.108122 140280725968768 learning.py:507] global step 41: loss = 7.8558 (0.706 sec/step)\n",
            "I0718 09:13:05.789454 140280725968768 learning.py:507] global step 42: loss = 8.0598 (0.679 sec/step)\n",
            "I0718 09:13:06.462795 140280725968768 learning.py:507] global step 43: loss = 7.2916 (0.671 sec/step)\n",
            "I0718 09:13:07.149901 140280725968768 learning.py:507] global step 44: loss = 7.1582 (0.685 sec/step)\n",
            "I0718 09:13:07.829988 140280725968768 learning.py:507] global step 45: loss = 7.6691 (0.678 sec/step)\n",
            "I0718 09:13:08.485202 140280725968768 learning.py:507] global step 46: loss = 7.6851 (0.653 sec/step)\n",
            "I0718 09:13:09.171734 140280725968768 learning.py:507] global step 47: loss = 7.5965 (0.684 sec/step)\n",
            "I0718 09:13:09.840970 140280725968768 learning.py:507] global step 48: loss = 7.2416 (0.667 sec/step)\n",
            "I0718 09:13:10.509376 140280725968768 learning.py:507] global step 49: loss = 6.9613 (0.667 sec/step)\n",
            "I0718 09:13:11.179322 140280725968768 learning.py:507] global step 50: loss = 7.1099 (0.668 sec/step)\n",
            "I0718 09:13:11.896394 140280725968768 learning.py:507] global step 51: loss = 7.2326 (0.715 sec/step)\n",
            "I0718 09:13:12.637205 140280725968768 learning.py:507] global step 52: loss = 7.4127 (0.739 sec/step)\n",
            "I0718 09:13:13.495763 140280725968768 learning.py:507] global step 53: loss = 6.8332 (0.856 sec/step)\n",
            "I0718 09:13:14.230384 140280725968768 learning.py:507] global step 54: loss = 7.3219 (0.733 sec/step)\n",
            "I0718 09:13:14.937203 140280725968768 learning.py:507] global step 55: loss = 6.6689 (0.705 sec/step)\n",
            "I0718 09:13:15.611515 140280725968768 learning.py:507] global step 56: loss = 7.1982 (0.672 sec/step)\n",
            "I0718 09:13:16.314038 140280725968768 learning.py:507] global step 57: loss = 6.8420 (0.701 sec/step)\n",
            "I0718 09:13:16.989009 140280725968768 learning.py:507] global step 58: loss = 7.0323 (0.673 sec/step)\n",
            "I0718 09:13:17.659362 140280725968768 learning.py:507] global step 59: loss = 6.8440 (0.669 sec/step)\n",
            "I0718 09:13:18.318500 140280725968768 learning.py:507] global step 60: loss = 6.7467 (0.657 sec/step)\n",
            "I0718 09:13:18.982809 140280725968768 learning.py:507] global step 61: loss = 7.3290 (0.662 sec/step)\n",
            "I0718 09:13:19.667006 140280725968768 learning.py:507] global step 62: loss = 6.5021 (0.682 sec/step)\n",
            "I0718 09:13:20.323688 140280725968768 learning.py:507] global step 63: loss = 6.3419 (0.655 sec/step)\n",
            "I0718 09:13:20.990771 140280725968768 learning.py:507] global step 64: loss = 6.4764 (0.665 sec/step)\n",
            "I0718 09:13:21.682721 140280725968768 learning.py:507] global step 65: loss = 7.3777 (0.690 sec/step)\n",
            "I0718 09:13:22.359242 140280725968768 learning.py:507] global step 66: loss = 6.7598 (0.675 sec/step)\n",
            "I0718 09:13:23.024379 140280725968768 learning.py:507] global step 67: loss = 6.3795 (0.663 sec/step)\n",
            "I0718 09:13:23.706531 140280725968768 learning.py:507] global step 68: loss = 6.5285 (0.680 sec/step)\n",
            "I0718 09:13:24.385823 140280725968768 learning.py:507] global step 69: loss = 6.7992 (0.678 sec/step)\n",
            "I0718 09:13:25.067026 140280725968768 learning.py:507] global step 70: loss = 6.5428 (0.679 sec/step)\n",
            "I0718 09:13:25.740726 140280725968768 learning.py:507] global step 71: loss = 6.8946 (0.672 sec/step)\n",
            "I0718 09:13:26.419639 140280725968768 learning.py:507] global step 72: loss = 6.6978 (0.677 sec/step)\n",
            "I0718 09:13:27.113723 140280725968768 learning.py:507] global step 73: loss = 6.0331 (0.692 sec/step)\n",
            "I0718 09:13:27.814722 140280725968768 learning.py:507] global step 74: loss = 5.8505 (0.698 sec/step)\n",
            "I0718 09:13:28.493316 140280725968768 learning.py:507] global step 75: loss = 6.8172 (0.677 sec/step)\n",
            "I0718 09:13:29.155443 140280725968768 learning.py:507] global step 76: loss = 6.2099 (0.660 sec/step)\n",
            "I0718 09:13:29.836817 140280725968768 learning.py:507] global step 77: loss = 6.4168 (0.679 sec/step)\n",
            "I0718 09:13:30.506269 140280725968768 learning.py:507] global step 78: loss = 6.1292 (0.668 sec/step)\n",
            "I0718 09:13:31.184607 140280725968768 learning.py:507] global step 79: loss = 5.8832 (0.676 sec/step)\n",
            "I0718 09:13:31.873225 140280725968768 learning.py:507] global step 80: loss = 5.5167 (0.687 sec/step)\n",
            "I0718 09:13:32.540998 140280725968768 learning.py:507] global step 81: loss = 6.5688 (0.666 sec/step)\n",
            "I0718 09:13:33.217050 140280725968768 learning.py:507] global step 82: loss = 6.5456 (0.674 sec/step)\n",
            "I0718 09:13:33.900008 140280725968768 learning.py:507] global step 83: loss = 5.3505 (0.681 sec/step)\n",
            "I0718 09:13:34.551069 140280725968768 learning.py:507] global step 84: loss = 7.0242 (0.649 sec/step)\n",
            "I0718 09:13:35.216892 140280725968768 learning.py:507] global step 85: loss = 6.4880 (0.664 sec/step)\n",
            "I0718 09:13:35.881155 140280725968768 learning.py:507] global step 86: loss = 5.5282 (0.663 sec/step)\n",
            "I0718 09:13:36.544630 140280725968768 learning.py:507] global step 87: loss = 5.4531 (0.662 sec/step)\n",
            "I0718 09:13:37.264384 140280725968768 learning.py:507] global step 88: loss = 5.7917 (0.718 sec/step)\n",
            "I0718 09:13:37.937802 140280725968768 learning.py:507] global step 89: loss = 6.1286 (0.672 sec/step)\n",
            "I0718 09:13:38.610111 140280725968768 learning.py:507] global step 90: loss = 6.5422 (0.671 sec/step)\n",
            "I0718 09:13:39.285460 140280725968768 learning.py:507] global step 91: loss = 5.9257 (0.673 sec/step)\n",
            "I0718 09:13:39.945325 140280725968768 learning.py:507] global step 92: loss = 6.0793 (0.658 sec/step)\n",
            "I0718 09:13:40.613640 140280725968768 learning.py:507] global step 93: loss = 5.2942 (0.667 sec/step)\n",
            "I0718 09:13:41.326556 140280725968768 learning.py:507] global step 94: loss = 6.0239 (0.711 sec/step)\n",
            "I0718 09:13:41.989957 140280725968768 learning.py:507] global step 95: loss = 5.6295 (0.660 sec/step)\n",
            "I0718 09:13:42.658468 140280725968768 learning.py:507] global step 96: loss = 5.7068 (0.666 sec/step)\n",
            "I0718 09:13:43.348479 140280725968768 learning.py:507] global step 97: loss = 5.5035 (0.688 sec/step)\n",
            "I0718 09:13:44.050790 140280725968768 learning.py:507] global step 98: loss = 5.3232 (0.699 sec/step)\n",
            "I0718 09:13:44.708971 140280725968768 learning.py:507] global step 99: loss = 5.5567 (0.656 sec/step)\n",
            "I0718 09:13:45.365070 140280725968768 learning.py:507] global step 100: loss = 5.6421 (0.654 sec/step)\n",
            "I0718 09:13:46.042899 140280725968768 learning.py:507] global step 101: loss = 4.6092 (0.676 sec/step)\n",
            "I0718 09:13:46.695246 140280725968768 learning.py:507] global step 102: loss = 5.0678 (0.651 sec/step)\n",
            "I0718 09:13:47.413385 140280725968768 learning.py:507] global step 103: loss = 5.5481 (0.716 sec/step)\n",
            "I0718 09:13:48.084198 140280725968768 learning.py:507] global step 104: loss = 4.8724 (0.669 sec/step)\n",
            "I0718 09:13:48.755185 140280725968768 learning.py:507] global step 105: loss = 5.3807 (0.669 sec/step)\n",
            "I0718 09:13:49.426878 140280725968768 learning.py:507] global step 106: loss = 5.0408 (0.670 sec/step)\n",
            "I0718 09:13:50.091566 140280725968768 learning.py:507] global step 107: loss = 4.7453 (0.663 sec/step)\n",
            "I0718 09:13:50.757978 140280725968768 learning.py:507] global step 108: loss = 5.6822 (0.665 sec/step)\n",
            "I0718 09:13:51.428171 140280725968768 learning.py:507] global step 109: loss = 5.8662 (0.669 sec/step)\n",
            "I0718 09:13:52.078279 140280725968768 learning.py:507] global step 110: loss = 5.2794 (0.648 sec/step)\n",
            "I0718 09:13:52.749343 140280725968768 learning.py:507] global step 111: loss = 4.7592 (0.669 sec/step)\n",
            "I0718 09:13:53.430782 140280725968768 learning.py:507] global step 112: loss = 4.7967 (0.680 sec/step)\n",
            "I0718 09:13:54.109121 140280725968768 learning.py:507] global step 113: loss = 5.2744 (0.677 sec/step)\n",
            "I0718 09:13:54.786696 140280725968768 learning.py:507] global step 114: loss = 4.9479 (0.676 sec/step)\n",
            "I0718 09:13:55.437822 140280725968768 learning.py:507] global step 115: loss = 5.0612 (0.649 sec/step)\n",
            "I0718 09:13:56.087651 140280725968768 learning.py:507] global step 116: loss = 4.4733 (0.648 sec/step)\n",
            "I0718 09:13:56.807507 140280725968768 learning.py:507] global step 117: loss = 6.8626 (0.718 sec/step)\n",
            "I0718 09:13:57.469722 140280725968768 learning.py:507] global step 118: loss = 5.5353 (0.660 sec/step)\n",
            "I0718 09:13:58.138857 140280725968768 learning.py:507] global step 119: loss = 5.2349 (0.667 sec/step)\n",
            "I0718 09:13:58.824172 140280725968768 learning.py:507] global step 120: loss = 4.8834 (0.683 sec/step)\n",
            "I0718 09:13:59.503397 140280725968768 learning.py:507] global step 121: loss = 5.9077 (0.677 sec/step)\n",
            "I0718 09:14:00.207275 140280725968768 learning.py:507] global step 122: loss = 4.4124 (0.702 sec/step)\n",
            "I0718 09:14:00.894077 140280725968768 learning.py:507] global step 123: loss = 4.9595 (0.685 sec/step)\n",
            "I0718 09:14:01.559060 140280725968768 learning.py:507] global step 124: loss = 4.4382 (0.662 sec/step)\n",
            "I0718 09:14:02.241937 140280725968768 learning.py:507] global step 125: loss = 5.1570 (0.681 sec/step)\n",
            "I0718 09:14:02.896878 140280725968768 learning.py:507] global step 126: loss = 5.0175 (0.653 sec/step)\n",
            "I0718 09:14:03.574936 140280725968768 learning.py:507] global step 127: loss = 5.5436 (0.676 sec/step)\n",
            "I0718 09:14:04.254942 140280725968768 learning.py:507] global step 128: loss = 5.6390 (0.678 sec/step)\n",
            "I0718 09:14:04.925172 140280725968768 learning.py:507] global step 129: loss = 4.3388 (0.668 sec/step)\n",
            "I0718 09:14:05.565371 140280725968768 learning.py:507] global step 130: loss = 5.2308 (0.639 sec/step)\n",
            "I0718 09:14:06.236497 140280725968768 learning.py:507] global step 131: loss = 3.9331 (0.669 sec/step)\n",
            "I0718 09:14:06.905186 140280725968768 learning.py:507] global step 132: loss = 4.4252 (0.667 sec/step)\n",
            "I0718 09:14:07.566376 140280725968768 learning.py:507] global step 133: loss = 5.0214 (0.659 sec/step)\n",
            "I0718 09:14:08.260827 140280725968768 learning.py:507] global step 134: loss = 4.7002 (0.693 sec/step)\n",
            "I0718 09:14:08.922026 140280725968768 learning.py:507] global step 135: loss = 3.7235 (0.659 sec/step)\n",
            "I0718 09:14:09.570126 140280725968768 learning.py:507] global step 136: loss = 5.8062 (0.646 sec/step)\n",
            "I0718 09:14:10.246159 140280725968768 learning.py:507] global step 137: loss = 3.9378 (0.674 sec/step)\n",
            "I0718 09:14:10.949151 140280725968768 learning.py:507] global step 138: loss = 4.0683 (0.701 sec/step)\n",
            "I0718 09:14:11.592628 140280725968768 learning.py:507] global step 139: loss = 4.7295 (0.642 sec/step)\n",
            "I0718 09:14:12.281121 140280725968768 learning.py:507] global step 140: loss = 3.7125 (0.686 sec/step)\n",
            "I0718 09:14:12.984623 140280725968768 learning.py:507] global step 141: loss = 4.7620 (0.702 sec/step)\n",
            "I0718 09:14:13.803208 140280725968768 learning.py:507] global step 142: loss = 4.1807 (0.817 sec/step)\n",
            "I0718 09:14:14.617317 140280725968768 learning.py:507] global step 143: loss = 4.5942 (0.812 sec/step)\n",
            "I0718 09:14:15.288714 140280725968768 learning.py:507] global step 144: loss = 5.6480 (0.670 sec/step)\n",
            "I0718 09:14:15.969299 140280725968768 learning.py:507] global step 145: loss = 3.8671 (0.679 sec/step)\n",
            "I0718 09:14:16.653905 140280725968768 learning.py:507] global step 146: loss = 3.4602 (0.683 sec/step)\n",
            "I0718 09:14:17.331156 140280725968768 learning.py:507] global step 147: loss = 4.7432 (0.675 sec/step)\n",
            "I0718 09:14:18.532196 140280725968768 learning.py:507] global step 148: loss = 4.0192 (1.180 sec/step)\n",
            "I0718 09:14:18.620980 140277976831744 supervisor.py:1050] Recording summary at step 148.\n",
            "I0718 09:14:19.220249 140280725968768 learning.py:507] global step 149: loss = 4.3791 (0.686 sec/step)\n",
            "I0718 09:14:19.898550 140280725968768 learning.py:507] global step 150: loss = 4.0343 (0.677 sec/step)\n",
            "I0718 09:14:20.097478 140279010821888 supervisor.py:1099] global_step/sec: 1.33632\n",
            "I0718 09:14:20.590015 140280725968768 learning.py:507] global step 151: loss = 4.2860 (0.689 sec/step)\n",
            "I0718 09:14:21.245101 140280725968768 learning.py:507] global step 152: loss = 3.5110 (0.653 sec/step)\n",
            "I0718 09:14:21.921077 140280725968768 learning.py:507] global step 153: loss = 3.8497 (0.674 sec/step)\n",
            "I0718 09:14:22.598471 140280725968768 learning.py:507] global step 154: loss = 4.2049 (0.676 sec/step)\n",
            "I0718 09:14:23.274734 140280725968768 learning.py:507] global step 155: loss = 4.9541 (0.674 sec/step)\n",
            "I0718 09:14:23.941509 140280725968768 learning.py:507] global step 156: loss = 3.7771 (0.665 sec/step)\n",
            "I0718 09:14:24.623300 140280725968768 learning.py:507] global step 157: loss = 4.3104 (0.680 sec/step)\n",
            "I0718 09:14:25.290579 140280725968768 learning.py:507] global step 158: loss = 4.3337 (0.665 sec/step)\n",
            "I0718 09:14:26.004394 140280725968768 learning.py:507] global step 159: loss = 4.3840 (0.712 sec/step)\n",
            "I0718 09:14:26.707409 140280725968768 learning.py:507] global step 160: loss = 4.8407 (0.701 sec/step)\n",
            "I0718 09:14:27.372841 140280725968768 learning.py:507] global step 161: loss = 4.9474 (0.663 sec/step)\n",
            "I0718 09:14:28.055949 140280725968768 learning.py:507] global step 162: loss = 4.5025 (0.681 sec/step)\n",
            "I0718 09:14:28.770998 140280725968768 learning.py:507] global step 163: loss = 4.3281 (0.713 sec/step)\n",
            "I0718 09:14:29.452913 140280725968768 learning.py:507] global step 164: loss = 4.4506 (0.680 sec/step)\n",
            "I0718 09:14:30.106209 140280725968768 learning.py:507] global step 165: loss = 4.6657 (0.652 sec/step)\n",
            "I0718 09:14:30.805092 140280725968768 learning.py:507] global step 166: loss = 4.1845 (0.697 sec/step)\n",
            "I0718 09:14:31.457621 140280725968768 learning.py:507] global step 167: loss = 3.3867 (0.651 sec/step)\n",
            "I0718 09:14:32.137939 140280725968768 learning.py:507] global step 168: loss = 4.3722 (0.678 sec/step)\n",
            "I0718 09:14:32.787452 140280725968768 learning.py:507] global step 169: loss = 3.4251 (0.648 sec/step)\n",
            "I0718 09:14:33.463085 140280725968768 learning.py:507] global step 170: loss = 4.7264 (0.674 sec/step)\n",
            "I0718 09:14:34.138954 140280725968768 learning.py:507] global step 171: loss = 4.3100 (0.674 sec/step)\n",
            "I0718 09:14:34.820285 140280725968768 learning.py:507] global step 172: loss = 3.8238 (0.679 sec/step)\n",
            "I0718 09:14:35.508750 140280725968768 learning.py:507] global step 173: loss = 4.0569 (0.686 sec/step)\n",
            "I0718 09:14:36.166301 140280725968768 learning.py:507] global step 174: loss = 3.9855 (0.656 sec/step)\n",
            "I0718 09:14:36.845036 140280725968768 learning.py:507] global step 175: loss = 3.8498 (0.677 sec/step)\n",
            "I0718 09:14:37.493157 140280725968768 learning.py:507] global step 176: loss = 4.5683 (0.646 sec/step)\n",
            "I0718 09:14:38.174450 140280725968768 learning.py:507] global step 177: loss = 3.3755 (0.680 sec/step)\n",
            "I0718 09:14:38.832689 140280725968768 learning.py:507] global step 178: loss = 4.9443 (0.656 sec/step)\n",
            "I0718 09:14:39.534393 140280725968768 learning.py:507] global step 179: loss = 3.5672 (0.700 sec/step)\n",
            "I0718 09:14:40.207082 140280725968768 learning.py:507] global step 180: loss = 3.7115 (0.671 sec/step)\n",
            "I0718 09:14:40.884218 140280725968768 learning.py:507] global step 181: loss = 4.0969 (0.675 sec/step)\n",
            "I0718 09:14:41.580331 140280725968768 learning.py:507] global step 182: loss = 4.2214 (0.694 sec/step)\n",
            "I0718 09:14:42.249556 140280725968768 learning.py:507] global step 183: loss = 3.9697 (0.667 sec/step)\n",
            "I0718 09:14:42.928683 140280725968768 learning.py:507] global step 184: loss = 3.8652 (0.677 sec/step)\n",
            "I0718 09:14:43.609618 140280725968768 learning.py:507] global step 185: loss = 3.7084 (0.679 sec/step)\n",
            "I0718 09:14:44.285933 140280725968768 learning.py:507] global step 186: loss = 3.3308 (0.674 sec/step)\n",
            "I0718 09:14:44.964249 140280725968768 learning.py:507] global step 187: loss = 4.0375 (0.677 sec/step)\n",
            "I0718 09:14:45.648749 140280725968768 learning.py:507] global step 188: loss = 4.4912 (0.683 sec/step)\n",
            "I0718 09:14:46.324070 140280725968768 learning.py:507] global step 189: loss = 4.4087 (0.673 sec/step)\n",
            "I0718 09:14:46.986010 140280725968768 learning.py:507] global step 190: loss = 4.8637 (0.660 sec/step)\n",
            "I0718 09:14:47.649858 140280725968768 learning.py:507] global step 191: loss = 3.6101 (0.662 sec/step)\n",
            "I0718 09:14:48.388952 140280725968768 learning.py:507] global step 192: loss = 3.3618 (0.737 sec/step)\n",
            "I0718 09:14:49.058619 140280725968768 learning.py:507] global step 193: loss = 3.4244 (0.668 sec/step)\n",
            "I0718 09:14:49.726753 140280725968768 learning.py:507] global step 194: loss = 3.5878 (0.666 sec/step)\n",
            "I0718 09:14:50.397103 140280725968768 learning.py:507] global step 195: loss = 3.7736 (0.669 sec/step)\n",
            "I0718 09:14:51.048885 140280725968768 learning.py:507] global step 196: loss = 3.4473 (0.650 sec/step)\n",
            "I0718 09:14:51.728133 140280725968768 learning.py:507] global step 197: loss = 4.7061 (0.677 sec/step)\n",
            "I0718 09:14:52.413744 140280725968768 learning.py:507] global step 198: loss = 4.1643 (0.684 sec/step)\n",
            "I0718 09:14:53.092678 140280725968768 learning.py:507] global step 199: loss = 4.2724 (0.677 sec/step)\n",
            "I0718 09:14:53.752542 140280725968768 learning.py:507] global step 200: loss = 4.2103 (0.657 sec/step)\n",
            "I0718 09:14:54.441465 140280725968768 learning.py:507] global step 201: loss = 4.0814 (0.687 sec/step)\n",
            "I0718 09:14:55.102264 140280725968768 learning.py:507] global step 202: loss = 3.7259 (0.659 sec/step)\n",
            "I0718 09:14:55.797683 140280725968768 learning.py:507] global step 203: loss = 3.6027 (0.693 sec/step)\n",
            "I0718 09:14:56.480810 140280725968768 learning.py:507] global step 204: loss = 3.4315 (0.681 sec/step)\n",
            "I0718 09:14:57.131993 140280725968768 learning.py:507] global step 205: loss = 4.5411 (0.649 sec/step)\n",
            "I0718 09:14:57.803179 140280725968768 learning.py:507] global step 206: loss = 3.6268 (0.669 sec/step)\n",
            "I0718 09:14:58.461716 140280725968768 learning.py:507] global step 207: loss = 3.6726 (0.657 sec/step)\n",
            "I0718 09:14:59.131870 140280725968768 learning.py:507] global step 208: loss = 3.8027 (0.668 sec/step)\n",
            "I0718 09:14:59.828963 140280725968768 learning.py:507] global step 209: loss = 4.7532 (0.695 sec/step)\n",
            "I0718 09:15:00.488683 140280725968768 learning.py:507] global step 210: loss = 4.3388 (0.657 sec/step)\n",
            "I0718 09:15:01.172727 140280725968768 learning.py:507] global step 211: loss = 3.8313 (0.682 sec/step)\n",
            "I0718 09:15:01.831089 140280725968768 learning.py:507] global step 212: loss = 4.5732 (0.656 sec/step)\n",
            "I0718 09:15:02.492296 140280725968768 learning.py:507] global step 213: loss = 4.2844 (0.659 sec/step)\n",
            "I0718 09:15:03.144705 140280725968768 learning.py:507] global step 214: loss = 3.9361 (0.650 sec/step)\n",
            "I0718 09:15:03.849920 140280725968768 learning.py:507] global step 215: loss = 4.2169 (0.703 sec/step)\n",
            "I0718 09:15:04.511321 140280725968768 learning.py:507] global step 216: loss = 4.2422 (0.659 sec/step)\n",
            "I0718 09:15:05.171578 140280725968768 learning.py:507] global step 217: loss = 2.8926 (0.658 sec/step)\n",
            "I0718 09:15:05.845859 140280725968768 learning.py:507] global step 218: loss = 4.3276 (0.673 sec/step)\n",
            "I0718 09:15:06.522023 140280725968768 learning.py:507] global step 219: loss = 4.3463 (0.675 sec/step)\n",
            "I0718 09:15:07.213384 140280725968768 learning.py:507] global step 220: loss = 4.6655 (0.689 sec/step)\n",
            "I0718 09:15:07.903730 140280725968768 learning.py:507] global step 221: loss = 3.4750 (0.688 sec/step)\n",
            "I0718 09:15:08.553348 140280725968768 learning.py:507] global step 222: loss = 3.8963 (0.648 sec/step)\n",
            "I0718 09:15:09.239433 140280725968768 learning.py:507] global step 223: loss = 3.9077 (0.684 sec/step)\n",
            "I0718 09:15:09.932141 140280725968768 learning.py:507] global step 224: loss = 3.4991 (0.691 sec/step)\n",
            "I0718 09:15:10.621475 140280725968768 learning.py:507] global step 225: loss = 3.9768 (0.687 sec/step)\n",
            "I0718 09:15:11.276636 140280725968768 learning.py:507] global step 226: loss = 3.2438 (0.653 sec/step)\n",
            "I0718 09:15:11.944152 140280725968768 learning.py:507] global step 227: loss = 3.2260 (0.666 sec/step)\n",
            "I0718 09:15:12.641244 140280725968768 learning.py:507] global step 228: loss = 3.8729 (0.695 sec/step)\n",
            "I0718 09:15:13.385035 140280725968768 learning.py:507] global step 229: loss = 5.1898 (0.742 sec/step)\n",
            "I0718 09:15:14.203110 140280725968768 learning.py:507] global step 230: loss = 3.1465 (0.816 sec/step)\n",
            "I0718 09:15:14.978769 140280725968768 learning.py:507] global step 231: loss = 4.9508 (0.774 sec/step)\n",
            "I0718 09:15:15.688262 140280725968768 learning.py:507] global step 232: loss = 3.7996 (0.708 sec/step)\n",
            "I0718 09:15:16.359378 140280725968768 learning.py:507] global step 233: loss = 3.3626 (0.669 sec/step)\n",
            "I0718 09:15:17.034563 140280725968768 learning.py:507] global step 234: loss = 3.3661 (0.673 sec/step)\n",
            "I0718 09:15:17.700605 140280725968768 learning.py:507] global step 235: loss = 4.0224 (0.664 sec/step)\n",
            "I0718 09:15:18.387867 140280725968768 learning.py:507] global step 236: loss = 3.3161 (0.685 sec/step)\n",
            "I0718 09:15:19.058564 140280725968768 learning.py:507] global step 237: loss = 3.3129 (0.669 sec/step)\n",
            "I0718 09:15:19.717862 140280725968768 learning.py:507] global step 238: loss = 4.1940 (0.657 sec/step)\n",
            "I0718 09:15:20.416151 140280725968768 learning.py:507] global step 239: loss = 5.4673 (0.696 sec/step)\n",
            "I0718 09:15:21.071652 140280725968768 learning.py:507] global step 240: loss = 3.7214 (0.654 sec/step)\n",
            "I0718 09:15:21.748518 140280725968768 learning.py:507] global step 241: loss = 3.6520 (0.675 sec/step)\n",
            "I0718 09:15:22.434494 140280725968768 learning.py:507] global step 242: loss = 3.1890 (0.684 sec/step)\n",
            "I0718 09:15:23.101844 140280725968768 learning.py:507] global step 243: loss = 3.6101 (0.666 sec/step)\n",
            "I0718 09:15:23.777606 140280725968768 learning.py:507] global step 244: loss = 4.3053 (0.674 sec/step)\n",
            "I0718 09:15:24.463643 140280725968768 learning.py:507] global step 245: loss = 4.7010 (0.684 sec/step)\n",
            "I0718 09:15:25.138600 140280725968768 learning.py:507] global step 246: loss = 3.4473 (0.672 sec/step)\n",
            "I0718 09:15:25.803420 140280725968768 learning.py:507] global step 247: loss = 2.9565 (0.662 sec/step)\n",
            "I0718 09:15:26.480061 140280725968768 learning.py:507] global step 248: loss = 4.6886 (0.675 sec/step)\n",
            "I0718 09:15:27.170603 140280725968768 learning.py:507] global step 249: loss = 3.2943 (0.689 sec/step)\n",
            "I0718 09:15:27.848920 140280725968768 learning.py:507] global step 250: loss = 4.0579 (0.677 sec/step)\n",
            "I0718 09:15:28.523228 140280725968768 learning.py:507] global step 251: loss = 4.1596 (0.673 sec/step)\n",
            "I0718 09:15:29.192262 140280725968768 learning.py:507] global step 252: loss = 4.0014 (0.667 sec/step)\n",
            "I0718 09:15:29.871628 140280725968768 learning.py:507] global step 253: loss = 3.3992 (0.677 sec/step)\n",
            "I0718 09:15:30.555834 140280725968768 learning.py:507] global step 254: loss = 3.1843 (0.682 sec/step)\n",
            "I0718 09:15:31.221230 140280725968768 learning.py:507] global step 255: loss = 3.5360 (0.663 sec/step)\n",
            "I0718 09:15:31.901770 140280725968768 learning.py:507] global step 256: loss = 3.3759 (0.679 sec/step)\n",
            "I0718 09:15:32.572375 140280725968768 learning.py:507] global step 257: loss = 4.1836 (0.669 sec/step)\n",
            "I0718 09:15:33.227253 140280725968768 learning.py:507] global step 258: loss = 2.8067 (0.653 sec/step)\n",
            "I0718 09:15:33.905951 140280725968768 learning.py:507] global step 259: loss = 3.3067 (0.677 sec/step)\n",
            "I0718 09:15:34.589583 140280725968768 learning.py:507] global step 260: loss = 3.0720 (0.682 sec/step)\n",
            "I0718 09:15:35.302954 140280725968768 learning.py:507] global step 261: loss = 2.9828 (0.711 sec/step)\n",
            "I0718 09:15:35.967398 140280725968768 learning.py:507] global step 262: loss = 2.9361 (0.663 sec/step)\n",
            "I0718 09:15:36.646733 140280725968768 learning.py:507] global step 263: loss = 3.9842 (0.677 sec/step)\n",
            "I0718 09:15:37.323271 140280725968768 learning.py:507] global step 264: loss = 4.2477 (0.675 sec/step)\n",
            "I0718 09:15:38.035697 140280725968768 learning.py:507] global step 265: loss = 3.9650 (0.711 sec/step)\n",
            "I0718 09:15:38.730757 140280725968768 learning.py:507] global step 266: loss = 2.8537 (0.693 sec/step)\n",
            "I0718 09:15:39.411607 140280725968768 learning.py:507] global step 267: loss = 3.0729 (0.679 sec/step)\n",
            "I0718 09:15:40.102140 140280725968768 learning.py:507] global step 268: loss = 3.8638 (0.689 sec/step)\n",
            "I0718 09:15:40.765877 140280725968768 learning.py:507] global step 269: loss = 3.2692 (0.662 sec/step)\n",
            "I0718 09:15:41.416997 140280725968768 learning.py:507] global step 270: loss = 5.1328 (0.649 sec/step)\n",
            "I0718 09:15:42.090470 140280725968768 learning.py:507] global step 271: loss = 3.8159 (0.671 sec/step)\n",
            "I0718 09:15:42.781378 140280725968768 learning.py:507] global step 272: loss = 3.8255 (0.689 sec/step)\n",
            "I0718 09:15:43.469762 140280725968768 learning.py:507] global step 273: loss = 3.4411 (0.687 sec/step)\n",
            "I0718 09:15:44.149997 140280725968768 learning.py:507] global step 274: loss = 3.7070 (0.678 sec/step)\n",
            "I0718 09:15:44.805196 140280725968768 learning.py:507] global step 275: loss = 3.1083 (0.653 sec/step)\n",
            "I0718 09:15:45.485946 140280725968768 learning.py:507] global step 276: loss = 3.7023 (0.679 sec/step)\n",
            "I0718 09:15:46.184474 140280725968768 learning.py:507] global step 277: loss = 4.1148 (0.697 sec/step)\n",
            "I0718 09:15:46.870854 140280725968768 learning.py:507] global step 278: loss = 3.2164 (0.685 sec/step)\n",
            "I0718 09:15:47.537814 140280725968768 learning.py:507] global step 279: loss = 3.1511 (0.665 sec/step)\n",
            "I0718 09:15:48.223946 140280725968768 learning.py:507] global step 280: loss = 3.6858 (0.681 sec/step)\n",
            "I0718 09:15:48.930151 140280725968768 learning.py:507] global step 281: loss = 3.7025 (0.704 sec/step)\n",
            "I0718 09:15:49.603102 140280725968768 learning.py:507] global step 282: loss = 2.8546 (0.671 sec/step)\n",
            "I0718 09:15:50.294816 140280725968768 learning.py:507] global step 283: loss = 2.9929 (0.690 sec/step)\n",
            "I0718 09:15:50.975021 140280725968768 learning.py:507] global step 284: loss = 3.1380 (0.678 sec/step)\n",
            "I0718 09:15:51.672329 140280725968768 learning.py:507] global step 285: loss = 3.5461 (0.695 sec/step)\n",
            "I0718 09:15:52.344920 140280725968768 learning.py:507] global step 286: loss = 2.7500 (0.671 sec/step)\n",
            "I0718 09:15:53.006335 140280725968768 learning.py:507] global step 287: loss = 3.2237 (0.659 sec/step)\n",
            "I0718 09:15:53.674084 140280725968768 learning.py:507] global step 288: loss = 2.9841 (0.666 sec/step)\n",
            "I0718 09:15:54.365844 140280725968768 learning.py:507] global step 289: loss = 3.0031 (0.690 sec/step)\n",
            "I0718 09:15:55.068838 140280725968768 learning.py:507] global step 290: loss = 3.2763 (0.701 sec/step)\n",
            "I0718 09:15:55.738896 140280725968768 learning.py:507] global step 291: loss = 3.2645 (0.668 sec/step)\n",
            "I0718 09:15:56.432207 140280725968768 learning.py:507] global step 292: loss = 3.4598 (0.692 sec/step)\n",
            "I0718 09:15:57.107074 140280725968768 learning.py:507] global step 293: loss = 3.1413 (0.671 sec/step)\n",
            "I0718 09:15:57.809423 140280725968768 learning.py:507] global step 294: loss = 3.2457 (0.700 sec/step)\n",
            "I0718 09:15:58.509120 140280725968768 learning.py:507] global step 295: loss = 3.0401 (0.698 sec/step)\n",
            "I0718 09:15:59.161036 140280725968768 learning.py:507] global step 296: loss = 3.8717 (0.648 sec/step)\n",
            "I0718 09:15:59.828601 140280725968768 learning.py:507] global step 297: loss = 3.7340 (0.666 sec/step)\n",
            "I0718 09:16:00.513728 140280725968768 learning.py:507] global step 298: loss = 3.4264 (0.683 sec/step)\n",
            "I0718 09:16:01.182066 140280725968768 learning.py:507] global step 299: loss = 3.4257 (0.666 sec/step)\n",
            "I0718 09:16:01.901996 140280725968768 learning.py:507] global step 300: loss = 3.2428 (0.718 sec/step)\n",
            "I0718 09:16:02.577827 140280725968768 learning.py:507] global step 301: loss = 3.2293 (0.674 sec/step)\n",
            "I0718 09:16:03.225028 140280725968768 learning.py:507] global step 302: loss = 3.5294 (0.645 sec/step)\n",
            "I0718 09:16:03.907405 140280725968768 learning.py:507] global step 303: loss = 4.1706 (0.680 sec/step)\n",
            "I0718 09:16:04.584367 140280725968768 learning.py:507] global step 304: loss = 3.3350 (0.675 sec/step)\n",
            "I0718 09:16:05.249560 140280725968768 learning.py:507] global step 305: loss = 4.0463 (0.663 sec/step)\n",
            "I0718 09:16:05.926594 140280725968768 learning.py:507] global step 306: loss = 3.2646 (0.675 sec/step)\n",
            "I0718 09:16:06.588377 140280725968768 learning.py:507] global step 307: loss = 3.3018 (0.660 sec/step)\n",
            "I0718 09:16:07.261342 140280725968768 learning.py:507] global step 308: loss = 3.8398 (0.671 sec/step)\n",
            "I0718 09:16:07.943487 140280725968768 learning.py:507] global step 309: loss = 3.1447 (0.680 sec/step)\n",
            "I0718 09:16:08.624477 140280725968768 learning.py:507] global step 310: loss = 3.3230 (0.679 sec/step)\n",
            "I0718 09:16:09.272875 140280725968768 learning.py:507] global step 311: loss = 4.2662 (0.647 sec/step)\n",
            "I0718 09:16:09.971130 140280725968768 learning.py:507] global step 312: loss = 3.1253 (0.697 sec/step)\n",
            "I0718 09:16:10.656009 140280725968768 learning.py:507] global step 313: loss = 3.2591 (0.683 sec/step)\n",
            "I0718 09:16:11.326106 140280725968768 learning.py:507] global step 314: loss = 3.4669 (0.668 sec/step)\n",
            "I0718 09:16:12.076986 140280725968768 learning.py:507] global step 315: loss = 2.8588 (0.749 sec/step)\n",
            "I0718 09:16:12.777126 140280725968768 learning.py:507] global step 316: loss = 3.4074 (0.698 sec/step)\n",
            "I0718 09:16:13.465552 140280725968768 learning.py:507] global step 317: loss = 3.0199 (0.687 sec/step)\n",
            "I0718 09:16:14.272832 140280725968768 learning.py:507] global step 318: loss = 3.3554 (0.805 sec/step)\n",
            "I0718 09:16:15.048390 140280725968768 learning.py:507] global step 319: loss = 3.7904 (0.774 sec/step)\n",
            "I0718 09:16:15.722986 140280725968768 learning.py:507] global step 320: loss = 4.3562 (0.672 sec/step)\n",
            "I0718 09:16:16.402833 140280725968768 learning.py:507] global step 321: loss = 3.1812 (0.678 sec/step)\n",
            "I0718 09:16:17.052322 140280725968768 learning.py:507] global step 322: loss = 3.2938 (0.647 sec/step)\n",
            "I0718 09:16:17.971582 140280725968768 learning.py:507] global step 323: loss = 4.9773 (0.917 sec/step)\n",
            "I0718 09:16:18.973240 140280725968768 learning.py:507] global step 324: loss = 3.1121 (0.999 sec/step)\n",
            "I0718 09:16:18.976374 140277976831744 supervisor.py:1050] Recording summary at step 324.\n",
            "I0718 09:16:19.646646 140280725968768 learning.py:507] global step 325: loss = 3.8049 (0.671 sec/step)\n",
            "I0718 09:16:20.119367 140279010821888 supervisor.py:1099] global_step/sec: 1.45807\n",
            "I0718 09:16:20.344555 140280725968768 learning.py:507] global step 326: loss = 3.7588 (0.696 sec/step)\n",
            "I0718 09:16:21.024587 140280725968768 learning.py:507] global step 327: loss = 3.2457 (0.678 sec/step)\n",
            "I0718 09:16:21.676529 140280725968768 learning.py:507] global step 328: loss = 3.1746 (0.650 sec/step)\n",
            "I0718 09:16:22.381150 140280725968768 learning.py:507] global step 329: loss = 3.9897 (0.703 sec/step)\n",
            "I0718 09:16:23.064220 140280725968768 learning.py:507] global step 330: loss = 3.6806 (0.681 sec/step)\n",
            "I0718 09:16:23.744934 140280725968768 learning.py:507] global step 331: loss = 3.5603 (0.679 sec/step)\n",
            "I0718 09:16:24.459728 140280725968768 learning.py:507] global step 332: loss = 3.4089 (0.713 sec/step)\n",
            "I0718 09:16:25.164963 140280725968768 learning.py:507] global step 333: loss = 4.3080 (0.704 sec/step)\n",
            "I0718 09:16:25.837492 140280725968768 learning.py:507] global step 334: loss = 3.4442 (0.671 sec/step)\n",
            "I0718 09:16:26.525371 140280725968768 learning.py:507] global step 335: loss = 3.3995 (0.686 sec/step)\n",
            "I0718 09:16:27.199304 140280725968768 learning.py:507] global step 336: loss = 3.6602 (0.672 sec/step)\n",
            "I0718 09:16:27.903754 140280725968768 learning.py:507] global step 337: loss = 3.3733 (0.702 sec/step)\n",
            "I0718 09:16:28.593367 140280725968768 learning.py:507] global step 338: loss = 4.2061 (0.688 sec/step)\n",
            "I0718 09:16:29.291408 140280725968768 learning.py:507] global step 339: loss = 3.2322 (0.696 sec/step)\n",
            "I0718 09:16:29.965755 140280725968768 learning.py:507] global step 340: loss = 3.2023 (0.673 sec/step)\n",
            "I0718 09:16:30.672418 140280725968768 learning.py:507] global step 341: loss = 3.2830 (0.705 sec/step)\n",
            "I0718 09:16:31.369615 140280725968768 learning.py:507] global step 342: loss = 3.0004 (0.695 sec/step)\n",
            "I0718 09:16:32.044771 140280725968768 learning.py:507] global step 343: loss = 2.4768 (0.673 sec/step)\n",
            "I0718 09:16:32.766953 140280725968768 learning.py:507] global step 344: loss = 3.0696 (0.721 sec/step)\n",
            "I0718 09:16:33.451774 140280725968768 learning.py:507] global step 345: loss = 2.9519 (0.683 sec/step)\n",
            "I0718 09:16:34.121610 140280725968768 learning.py:507] global step 346: loss = 3.3467 (0.668 sec/step)\n",
            "I0718 09:16:34.823124 140280725968768 learning.py:507] global step 347: loss = 3.8459 (0.699 sec/step)\n",
            "I0718 09:16:35.527641 140280725968768 learning.py:507] global step 348: loss = 4.3772 (0.703 sec/step)\n",
            "I0718 09:16:36.203109 140280725968768 learning.py:507] global step 349: loss = 3.3979 (0.674 sec/step)\n",
            "I0718 09:16:36.873381 140280725968768 learning.py:507] global step 350: loss = 3.1290 (0.669 sec/step)\n",
            "I0718 09:16:37.564078 140280725968768 learning.py:507] global step 351: loss = 3.5549 (0.689 sec/step)\n",
            "I0718 09:16:38.249775 140280725968768 learning.py:507] global step 352: loss = 3.2871 (0.684 sec/step)\n",
            "I0718 09:16:38.940843 140280725968768 learning.py:507] global step 353: loss = 3.8937 (0.689 sec/step)\n",
            "I0718 09:16:39.625693 140280725968768 learning.py:507] global step 354: loss = 4.1990 (0.683 sec/step)\n",
            "I0718 09:16:40.349465 140280725968768 learning.py:507] global step 355: loss = 4.2855 (0.722 sec/step)\n",
            "I0718 09:16:41.038523 140280725968768 learning.py:507] global step 356: loss = 4.5723 (0.687 sec/step)\n",
            "I0718 09:16:41.705141 140280725968768 learning.py:507] global step 357: loss = 4.0784 (0.664 sec/step)\n",
            "I0718 09:16:42.366086 140280725968768 learning.py:507] global step 358: loss = 3.9872 (0.659 sec/step)\n",
            "I0718 09:16:43.074877 140280725968768 learning.py:507] global step 359: loss = 3.6699 (0.707 sec/step)\n",
            "I0718 09:16:43.777827 140280725968768 learning.py:507] global step 360: loss = 3.4088 (0.701 sec/step)\n",
            "I0718 09:16:44.432615 140280725968768 learning.py:507] global step 361: loss = 3.0909 (0.653 sec/step)\n",
            "I0718 09:16:45.099861 140280725968768 learning.py:507] global step 362: loss = 2.7433 (0.665 sec/step)\n",
            "I0718 09:16:45.790525 140280725968768 learning.py:507] global step 363: loss = 3.0977 (0.689 sec/step)\n",
            "I0718 09:16:46.457043 140280725968768 learning.py:507] global step 364: loss = 3.0588 (0.664 sec/step)\n",
            "I0718 09:16:47.145068 140280725968768 learning.py:507] global step 365: loss = 3.4545 (0.686 sec/step)\n",
            "I0718 09:16:47.813979 140280725968768 learning.py:507] global step 366: loss = 2.9694 (0.667 sec/step)\n",
            "I0718 09:16:48.492302 140280725968768 learning.py:507] global step 367: loss = 2.6777 (0.676 sec/step)\n",
            "I0718 09:16:49.169001 140280725968768 learning.py:507] global step 368: loss = 2.9116 (0.675 sec/step)\n",
            "I0718 09:16:49.829640 140280725968768 learning.py:507] global step 369: loss = 2.4998 (0.659 sec/step)\n",
            "I0718 09:16:50.502367 140280725968768 learning.py:507] global step 370: loss = 3.0355 (0.671 sec/step)\n",
            "I0718 09:16:51.170930 140280725968768 learning.py:507] global step 371: loss = 2.7340 (0.667 sec/step)\n",
            "I0718 09:16:51.829771 140280725968768 learning.py:507] global step 372: loss = 3.4727 (0.657 sec/step)\n",
            "I0718 09:16:52.486383 140280725968768 learning.py:507] global step 373: loss = 2.8042 (0.655 sec/step)\n",
            "I0718 09:16:53.185916 140280725968768 learning.py:507] global step 374: loss = 4.0321 (0.698 sec/step)\n",
            "I0718 09:16:53.844803 140280725968768 learning.py:507] global step 375: loss = 3.3529 (0.654 sec/step)\n",
            "I0718 09:16:54.495187 140280725968768 learning.py:507] global step 376: loss = 3.0317 (0.649 sec/step)\n",
            "I0718 09:16:55.201505 140280725968768 learning.py:507] global step 377: loss = 3.1492 (0.705 sec/step)\n",
            "I0718 09:16:55.880338 140280725968768 learning.py:507] global step 378: loss = 3.6120 (0.677 sec/step)\n",
            "I0718 09:16:56.568099 140280725968768 learning.py:507] global step 379: loss = 2.9091 (0.686 sec/step)\n",
            "I0718 09:16:57.219756 140280725968768 learning.py:507] global step 380: loss = 3.0004 (0.650 sec/step)\n",
            "I0718 09:16:57.886638 140280725968768 learning.py:507] global step 381: loss = 3.4085 (0.665 sec/step)\n",
            "I0718 09:16:58.580728 140280725968768 learning.py:507] global step 382: loss = 3.2210 (0.692 sec/step)\n",
            "I0718 09:16:59.274183 140280725968768 learning.py:507] global step 383: loss = 2.5928 (0.692 sec/step)\n",
            "I0718 09:16:59.942654 140280725968768 learning.py:507] global step 384: loss = 2.6481 (0.667 sec/step)\n",
            "I0718 09:17:00.621576 140280725968768 learning.py:507] global step 385: loss = 3.1098 (0.677 sec/step)\n",
            "I0718 09:17:01.304758 140280725968768 learning.py:507] global step 386: loss = 2.8292 (0.681 sec/step)\n",
            "I0718 09:17:01.982108 140280725968768 learning.py:507] global step 387: loss = 2.6702 (0.676 sec/step)\n",
            "I0718 09:17:02.699341 140280725968768 learning.py:507] global step 388: loss = 2.1075 (0.715 sec/step)\n",
            "I0718 09:17:03.402543 140280725968768 learning.py:507] global step 389: loss = 2.9329 (0.701 sec/step)\n",
            "I0718 09:17:04.064906 140280725968768 learning.py:507] global step 390: loss = 3.1895 (0.661 sec/step)\n",
            "I0718 09:17:04.765784 140280725968768 learning.py:507] global step 391: loss = 3.5286 (0.699 sec/step)\n",
            "I0718 09:17:05.478230 140280725968768 learning.py:507] global step 392: loss = 3.1985 (0.711 sec/step)\n",
            "I0718 09:17:06.152361 140280725968768 learning.py:507] global step 393: loss = 3.0248 (0.672 sec/step)\n",
            "I0718 09:17:06.826135 140280725968768 learning.py:507] global step 394: loss = 3.1923 (0.672 sec/step)\n",
            "I0718 09:17:07.525449 140280725968768 learning.py:507] global step 395: loss = 3.5922 (0.697 sec/step)\n",
            "I0718 09:17:08.189090 140280725968768 learning.py:507] global step 396: loss = 2.6184 (0.662 sec/step)\n",
            "I0718 09:17:08.871069 140280725968768 learning.py:507] global step 397: loss = 2.6293 (0.680 sec/step)\n",
            "I0718 09:17:09.560757 140280725968768 learning.py:507] global step 398: loss = 2.8293 (0.688 sec/step)\n",
            "I0718 09:17:10.240182 140280725968768 learning.py:507] global step 399: loss = 2.4475 (0.677 sec/step)\n",
            "I0718 09:17:10.937308 140280725968768 learning.py:507] global step 400: loss = 2.8655 (0.695 sec/step)\n",
            "I0718 09:17:11.673153 140280725968768 learning.py:507] global step 401: loss = 2.6229 (0.734 sec/step)\n",
            "I0718 09:17:12.350286 140280725968768 learning.py:507] global step 402: loss = 3.7785 (0.675 sec/step)\n",
            "I0718 09:17:13.016034 140280725968768 learning.py:507] global step 403: loss = 2.9983 (0.664 sec/step)\n",
            "I0718 09:17:13.697733 140280725968768 learning.py:507] global step 404: loss = 3.5168 (0.680 sec/step)\n",
            "I0718 09:17:14.355277 140280725968768 learning.py:507] global step 405: loss = 2.6453 (0.656 sec/step)\n",
            "I0718 09:17:15.047870 140280725968768 learning.py:507] global step 406: loss = 3.3500 (0.691 sec/step)\n",
            "I0718 09:17:15.719600 140280725968768 learning.py:507] global step 407: loss = 3.1642 (0.670 sec/step)\n",
            "I0718 09:17:16.376879 140280725968768 learning.py:507] global step 408: loss = 2.3470 (0.655 sec/step)\n",
            "I0718 09:17:17.026582 140280725968768 learning.py:507] global step 409: loss = 2.8846 (0.648 sec/step)\n",
            "I0718 09:17:17.678917 140280725968768 learning.py:507] global step 410: loss = 3.7207 (0.650 sec/step)\n",
            "I0718 09:17:18.336752 140280725968768 learning.py:507] global step 411: loss = 3.9088 (0.656 sec/step)\n",
            "I0718 09:17:19.003708 140280725968768 learning.py:507] global step 412: loss = 3.4533 (0.665 sec/step)\n",
            "I0718 09:17:19.681464 140280725968768 learning.py:507] global step 413: loss = 3.3887 (0.676 sec/step)\n",
            "I0718 09:17:20.376936 140280725968768 learning.py:507] global step 414: loss = 3.3045 (0.694 sec/step)\n",
            "I0718 09:17:21.082498 140280725968768 learning.py:507] global step 415: loss = 2.8655 (0.704 sec/step)\n",
            "I0718 09:17:21.752565 140280725968768 learning.py:507] global step 416: loss = 3.2979 (0.667 sec/step)\n",
            "I0718 09:17:22.431989 140280725968768 learning.py:507] global step 417: loss = 2.5066 (0.678 sec/step)\n",
            "I0718 09:17:23.118017 140280725968768 learning.py:507] global step 418: loss = 3.0891 (0.684 sec/step)\n",
            "I0718 09:17:23.798232 140280725968768 learning.py:507] global step 419: loss = 3.1471 (0.678 sec/step)\n",
            "I0718 09:17:24.502871 140280725968768 learning.py:507] global step 420: loss = 2.7032 (0.703 sec/step)\n",
            "I0718 09:17:25.194876 140280725968768 learning.py:507] global step 421: loss = 3.2655 (0.690 sec/step)\n",
            "I0718 09:17:25.865610 140280725968768 learning.py:507] global step 422: loss = 2.6444 (0.669 sec/step)\n",
            "I0718 09:17:26.546193 140280725968768 learning.py:507] global step 423: loss = 3.7274 (0.679 sec/step)\n",
            "I0718 09:17:27.236642 140280725968768 learning.py:507] global step 424: loss = 2.2215 (0.688 sec/step)\n",
            "I0718 09:17:27.909504 140280725968768 learning.py:507] global step 425: loss = 3.7112 (0.669 sec/step)\n",
            "I0718 09:17:28.569260 140280725968768 learning.py:507] global step 426: loss = 2.4749 (0.658 sec/step)\n",
            "I0718 09:17:29.242357 140280725968768 learning.py:507] global step 427: loss = 3.1145 (0.671 sec/step)\n",
            "I0718 09:17:29.918161 140280725968768 learning.py:507] global step 428: loss = 3.2539 (0.674 sec/step)\n",
            "I0718 09:17:30.605138 140280725968768 learning.py:507] global step 429: loss = 2.3588 (0.685 sec/step)\n",
            "I0718 09:17:31.289505 140280725968768 learning.py:507] global step 430: loss = 3.5049 (0.683 sec/step)\n",
            "I0718 09:17:31.963862 140280725968768 learning.py:507] global step 431: loss = 3.7443 (0.673 sec/step)\n",
            "I0718 09:17:32.643718 140280725968768 learning.py:507] global step 432: loss = 3.7687 (0.678 sec/step)\n",
            "I0718 09:17:33.312811 140280725968768 learning.py:507] global step 433: loss = 2.8968 (0.667 sec/step)\n",
            "I0718 09:17:33.984537 140280725968768 learning.py:507] global step 434: loss = 3.0326 (0.670 sec/step)\n",
            "I0718 09:17:34.686972 140280725968768 learning.py:507] global step 435: loss = 3.9568 (0.700 sec/step)\n",
            "I0718 09:17:35.388750 140280725968768 learning.py:507] global step 436: loss = 3.3504 (0.700 sec/step)\n",
            "I0718 09:17:36.057197 140280725968768 learning.py:507] global step 437: loss = 3.8784 (0.666 sec/step)\n",
            "I0718 09:17:36.736158 140280725968768 learning.py:507] global step 438: loss = 2.8831 (0.677 sec/step)\n",
            "I0718 09:17:37.458784 140280725968768 learning.py:507] global step 439: loss = 3.0392 (0.720 sec/step)\n",
            "I0718 09:17:38.152088 140280725968768 learning.py:507] global step 440: loss = 3.3389 (0.691 sec/step)\n",
            "I0718 09:17:38.841875 140280725968768 learning.py:507] global step 441: loss = 2.8221 (0.688 sec/step)\n",
            "I0718 09:17:39.525865 140280725968768 learning.py:507] global step 442: loss = 4.0377 (0.682 sec/step)\n",
            "I0718 09:17:40.212563 140280725968768 learning.py:507] global step 443: loss = 2.3028 (0.685 sec/step)\n",
            "I0718 09:17:40.877026 140280725968768 learning.py:507] global step 444: loss = 3.7553 (0.663 sec/step)\n",
            "I0718 09:17:41.551481 140280725968768 learning.py:507] global step 445: loss = 2.8886 (0.673 sec/step)\n",
            "I0718 09:17:42.216020 140280725968768 learning.py:507] global step 446: loss = 2.6936 (0.662 sec/step)\n",
            "I0718 09:17:42.908071 140280725968768 learning.py:507] global step 447: loss = 3.0379 (0.690 sec/step)\n",
            "I0718 09:17:43.588160 140280725968768 learning.py:507] global step 448: loss = 2.5792 (0.678 sec/step)\n",
            "I0718 09:17:44.235979 140280725968768 learning.py:507] global step 449: loss = 2.6016 (0.646 sec/step)\n",
            "I0718 09:17:44.929127 140280725968768 learning.py:507] global step 450: loss = 3.0820 (0.691 sec/step)\n",
            "I0718 09:17:45.610319 140280725968768 learning.py:507] global step 451: loss = 3.1823 (0.679 sec/step)\n",
            "I0718 09:17:46.293048 140280725968768 learning.py:507] global step 452: loss = 3.6768 (0.680 sec/step)\n",
            "I0718 09:17:46.994342 140280725968768 learning.py:507] global step 453: loss = 3.6924 (0.699 sec/step)\n",
            "I0718 09:17:47.682196 140280725968768 learning.py:507] global step 454: loss = 2.5879 (0.686 sec/step)\n",
            "I0718 09:17:48.371784 140280725968768 learning.py:507] global step 455: loss = 3.2934 (0.688 sec/step)\n",
            "I0718 09:17:49.028164 140280725968768 learning.py:507] global step 456: loss = 3.3028 (0.655 sec/step)\n",
            "I0718 09:17:49.705435 140280725968768 learning.py:507] global step 457: loss = 3.0030 (0.675 sec/step)\n",
            "I0718 09:17:50.355456 140280725968768 learning.py:507] global step 458: loss = 3.1779 (0.648 sec/step)\n",
            "I0718 09:17:51.021962 140280725968768 learning.py:507] global step 459: loss = 2.5742 (0.665 sec/step)\n",
            "I0718 09:17:51.671265 140280725968768 learning.py:507] global step 460: loss = 2.9268 (0.648 sec/step)\n",
            "I0718 09:17:52.338358 140280725968768 learning.py:507] global step 461: loss = 3.2389 (0.665 sec/step)\n",
            "I0718 09:17:53.013088 140280725968768 learning.py:507] global step 462: loss = 2.9567 (0.673 sec/step)\n",
            "I0718 09:17:53.701012 140280725968768 learning.py:507] global step 463: loss = 3.9378 (0.685 sec/step)\n",
            "I0718 09:17:54.351632 140280725968768 learning.py:507] global step 464: loss = 3.2621 (0.648 sec/step)\n",
            "I0718 09:17:55.011046 140280725968768 learning.py:507] global step 465: loss = 3.5359 (0.658 sec/step)\n",
            "I0718 09:17:55.685092 140280725968768 learning.py:507] global step 466: loss = 3.4368 (0.672 sec/step)\n",
            "I0718 09:17:56.346727 140280725968768 learning.py:507] global step 467: loss = 2.8591 (0.660 sec/step)\n",
            "I0718 09:17:57.011470 140280725968768 learning.py:507] global step 468: loss = 3.9687 (0.663 sec/step)\n",
            "I0718 09:17:57.657841 140280725968768 learning.py:507] global step 469: loss = 2.9778 (0.645 sec/step)\n",
            "I0718 09:17:58.323471 140280725968768 learning.py:507] global step 470: loss = 2.7719 (0.664 sec/step)\n",
            "I0718 09:17:58.984730 140280725968768 learning.py:507] global step 471: loss = 1.8285 (0.659 sec/step)\n",
            "I0718 09:17:59.642180 140280725968768 learning.py:507] global step 472: loss = 3.4114 (0.656 sec/step)\n",
            "I0718 09:18:00.317203 140280725968768 learning.py:507] global step 473: loss = 2.3027 (0.673 sec/step)\n",
            "I0718 09:18:00.964397 140280725968768 learning.py:507] global step 474: loss = 3.3117 (0.645 sec/step)\n",
            "I0718 09:18:01.618560 140280725968768 learning.py:507] global step 475: loss = 2.5393 (0.652 sec/step)\n",
            "I0718 09:18:02.269426 140280725968768 learning.py:507] global step 476: loss = 3.2837 (0.649 sec/step)\n",
            "I0718 09:18:02.930529 140280725968768 learning.py:507] global step 477: loss = 3.2842 (0.659 sec/step)\n",
            "I0718 09:18:03.592410 140280725968768 learning.py:507] global step 478: loss = 3.5271 (0.660 sec/step)\n",
            "I0718 09:18:04.272519 140280725968768 learning.py:507] global step 479: loss = 3.7827 (0.678 sec/step)\n",
            "I0718 09:18:04.915905 140280725968768 learning.py:507] global step 480: loss = 3.3741 (0.641 sec/step)\n",
            "I0718 09:18:05.607647 140280725968768 learning.py:507] global step 481: loss = 2.6156 (0.690 sec/step)\n",
            "I0718 09:18:06.261997 140280725968768 learning.py:507] global step 482: loss = 2.9356 (0.653 sec/step)\n",
            "I0718 09:18:06.921729 140280725968768 learning.py:507] global step 483: loss = 3.3234 (0.658 sec/step)\n",
            "I0718 09:18:07.611468 140280725968768 learning.py:507] global step 484: loss = 3.2424 (0.688 sec/step)\n",
            "I0718 09:18:08.301787 140280725968768 learning.py:507] global step 485: loss = 3.4038 (0.689 sec/step)\n",
            "I0718 09:18:08.981375 140280725968768 learning.py:507] global step 486: loss = 3.3582 (0.678 sec/step)\n",
            "I0718 09:18:09.690033 140280725968768 learning.py:507] global step 487: loss = 3.4867 (0.707 sec/step)\n",
            "I0718 09:18:10.394121 140280725968768 learning.py:507] global step 488: loss = 2.7895 (0.702 sec/step)\n",
            "I0718 09:18:11.071740 140280725968768 learning.py:507] global step 489: loss = 2.7009 (0.676 sec/step)\n",
            "I0718 09:18:11.760242 140280725968768 learning.py:507] global step 490: loss = 2.8404 (0.687 sec/step)\n",
            "I0718 09:18:12.438935 140280725968768 learning.py:507] global step 491: loss = 2.5180 (0.677 sec/step)\n",
            "I0718 09:18:13.127103 140280725968768 learning.py:507] global step 492: loss = 2.5462 (0.686 sec/step)\n",
            "I0718 09:18:13.843914 140280725968768 learning.py:507] global step 493: loss = 2.8617 (0.715 sec/step)\n",
            "I0718 09:18:14.512093 140280725968768 learning.py:507] global step 494: loss = 2.2868 (0.666 sec/step)\n",
            "I0718 09:18:15.197532 140280725968768 learning.py:507] global step 495: loss = 3.0358 (0.684 sec/step)\n",
            "I0718 09:18:15.862942 140280725968768 learning.py:507] global step 496: loss = 2.6250 (0.664 sec/step)\n",
            "I0718 09:18:16.518185 140280725968768 learning.py:507] global step 497: loss = 3.0471 (0.654 sec/step)\n",
            "I0718 09:18:17.183290 140280725968768 learning.py:507] global step 498: loss = 3.6276 (0.663 sec/step)\n",
            "I0718 09:18:18.101459 140280725968768 learning.py:507] global step 499: loss = 2.2553 (0.836 sec/step)\n",
            "I0718 09:18:18.802289 140277976831744 supervisor.py:1050] Recording summary at step 499.\n",
            "I0718 09:18:19.065652 140280725968768 learning.py:507] global step 500: loss = 2.3943 (0.962 sec/step)\n",
            "I0718 09:18:19.758903 140280725968768 learning.py:507] global step 501: loss = 2.3325 (0.691 sec/step)\n",
            "I0718 09:18:20.176570 140279010821888 supervisor.py:1099] global_step/sec: 1.46597\n",
            "I0718 09:18:20.438431 140280725968768 learning.py:507] global step 502: loss = 3.7274 (0.676 sec/step)\n",
            "I0718 09:18:21.130908 140280725968768 learning.py:507] global step 503: loss = 2.5547 (0.691 sec/step)\n",
            "I0718 09:18:21.806368 140280725968768 learning.py:507] global step 504: loss = 3.2251 (0.674 sec/step)\n",
            "I0718 09:18:22.477429 140280725968768 learning.py:507] global step 505: loss = 2.8720 (0.669 sec/step)\n",
            "I0718 09:18:23.185639 140280725968768 learning.py:507] global step 506: loss = 3.4707 (0.706 sec/step)\n",
            "I0718 09:18:23.885683 140280725968768 learning.py:507] global step 507: loss = 2.9898 (0.698 sec/step)\n",
            "I0718 09:18:24.566891 140280725968768 learning.py:507] global step 508: loss = 2.2062 (0.679 sec/step)\n",
            "I0718 09:18:25.268603 140280725968768 learning.py:507] global step 509: loss = 2.6959 (0.700 sec/step)\n",
            "I0718 09:18:25.955976 140280725968768 learning.py:507] global step 510: loss = 3.6370 (0.686 sec/step)\n",
            "I0718 09:18:26.601528 140280725968768 learning.py:507] global step 511: loss = 2.7682 (0.644 sec/step)\n",
            "I0718 09:18:27.314601 140280725968768 learning.py:507] global step 512: loss = 3.2887 (0.711 sec/step)\n",
            "I0718 09:18:28.010595 140280725968768 learning.py:507] global step 513: loss = 2.4660 (0.694 sec/step)\n",
            "I0718 09:18:28.695872 140280725968768 learning.py:507] global step 514: loss = 3.3725 (0.683 sec/step)\n",
            "I0718 09:18:29.383066 140280725968768 learning.py:507] global step 515: loss = 3.1929 (0.685 sec/step)\n",
            "I0718 09:18:30.076117 140280725968768 learning.py:507] global step 516: loss = 3.6425 (0.691 sec/step)\n",
            "I0718 09:18:30.733749 140280725968768 learning.py:507] global step 517: loss = 3.3949 (0.656 sec/step)\n",
            "I0718 09:18:31.452422 140280725968768 learning.py:507] global step 518: loss = 3.0012 (0.717 sec/step)\n",
            "I0718 09:18:32.138175 140280725968768 learning.py:507] global step 519: loss = 2.9746 (0.684 sec/step)\n",
            "I0718 09:18:32.841775 140280725968768 learning.py:507] global step 520: loss = 2.7495 (0.702 sec/step)\n",
            "I0718 09:18:33.533707 140280725968768 learning.py:507] global step 521: loss = 3.0487 (0.690 sec/step)\n",
            "I0718 09:18:34.234915 140280725968768 learning.py:507] global step 522: loss = 2.7366 (0.700 sec/step)\n",
            "I0718 09:18:34.920303 140280725968768 learning.py:507] global step 523: loss = 2.5892 (0.684 sec/step)\n",
            "I0718 09:18:35.631301 140280725968768 learning.py:507] global step 524: loss = 2.6612 (0.709 sec/step)\n",
            "I0718 09:18:36.311324 140280725968768 learning.py:507] global step 525: loss = 2.7769 (0.678 sec/step)\n",
            "I0718 09:18:36.989926 140280725968768 learning.py:507] global step 526: loss = 2.4991 (0.677 sec/step)\n",
            "I0718 09:18:37.657357 140280725968768 learning.py:507] global step 527: loss = 2.4518 (0.665 sec/step)\n",
            "I0718 09:18:38.334280 140280725968768 learning.py:507] global step 528: loss = 3.0162 (0.675 sec/step)\n",
            "I0718 09:18:39.026831 140280725968768 learning.py:507] global step 529: loss = 2.3029 (0.691 sec/step)\n",
            "I0718 09:18:39.710040 140280725968768 learning.py:507] global step 530: loss = 2.1781 (0.681 sec/step)\n",
            "I0718 09:18:40.389065 140280725968768 learning.py:507] global step 531: loss = 2.7812 (0.677 sec/step)\n",
            "I0718 09:18:41.084099 140280725968768 learning.py:507] global step 532: loss = 3.4010 (0.693 sec/step)\n",
            "I0718 09:18:41.758750 140280725968768 learning.py:507] global step 533: loss = 3.1308 (0.673 sec/step)\n",
            "I0718 09:18:42.416535 140280725968768 learning.py:507] global step 534: loss = 2.9473 (0.655 sec/step)\n",
            "I0718 09:18:43.090107 140280725968768 learning.py:507] global step 535: loss = 2.8976 (0.672 sec/step)\n",
            "I0718 09:18:43.773884 140280725968768 learning.py:507] global step 536: loss = 3.2671 (0.682 sec/step)\n",
            "I0718 09:18:44.470630 140280725968768 learning.py:507] global step 537: loss = 2.1451 (0.695 sec/step)\n",
            "I0718 09:18:45.163323 140280725968768 learning.py:507] global step 538: loss = 2.3292 (0.691 sec/step)\n",
            "I0718 09:18:45.860520 140280725968768 learning.py:507] global step 539: loss = 3.6212 (0.695 sec/step)\n",
            "I0718 09:18:46.512420 140280725968768 learning.py:507] global step 540: loss = 2.6868 (0.650 sec/step)\n",
            "I0718 09:18:47.161790 140280725968768 learning.py:507] global step 541: loss = 2.8489 (0.647 sec/step)\n",
            "I0718 09:18:47.826997 140280725968768 learning.py:507] global step 542: loss = 3.0968 (0.663 sec/step)\n",
            "I0718 09:18:48.481647 140280725968768 learning.py:507] global step 543: loss = 2.2948 (0.653 sec/step)\n",
            "I0718 09:18:49.158054 140280725968768 learning.py:507] global step 544: loss = 3.4112 (0.675 sec/step)\n",
            "I0718 09:18:49.833431 140280725968768 learning.py:507] global step 545: loss = 2.9871 (0.673 sec/step)\n",
            "I0718 09:18:50.500576 140280725968768 learning.py:507] global step 546: loss = 3.1757 (0.665 sec/step)\n",
            "I0718 09:18:51.190991 140280725968768 learning.py:507] global step 547: loss = 2.7816 (0.689 sec/step)\n",
            "I0718 09:18:51.861012 140280725968768 learning.py:507] global step 548: loss = 2.8300 (0.668 sec/step)\n",
            "I0718 09:18:52.514345 140280725968768 learning.py:507] global step 549: loss = 2.8204 (0.652 sec/step)\n",
            "I0718 09:18:53.207979 140280725968768 learning.py:507] global step 550: loss = 2.9139 (0.692 sec/step)\n",
            "I0718 09:18:53.895596 140280725968768 learning.py:507] global step 551: loss = 3.6955 (0.686 sec/step)\n",
            "I0718 09:18:54.548098 140280725968768 learning.py:507] global step 552: loss = 2.1737 (0.650 sec/step)\n",
            "I0718 09:18:55.231268 140280725968768 learning.py:507] global step 553: loss = 2.3079 (0.682 sec/step)\n",
            "I0718 09:18:55.906399 140280725968768 learning.py:507] global step 554: loss = 2.6403 (0.673 sec/step)\n",
            "I0718 09:18:56.590652 140280725968768 learning.py:507] global step 555: loss = 4.3178 (0.682 sec/step)\n",
            "I0718 09:18:57.288056 140280725968768 learning.py:507] global step 556: loss = 2.6471 (0.696 sec/step)\n",
            "I0718 09:18:57.964716 140280725968768 learning.py:507] global step 557: loss = 2.7911 (0.675 sec/step)\n",
            "I0718 09:18:58.643087 140280725968768 learning.py:507] global step 558: loss = 2.5252 (0.677 sec/step)\n",
            "I0718 09:18:59.327381 140280725968768 learning.py:507] global step 559: loss = 2.7555 (0.682 sec/step)\n",
            "I0718 09:18:59.993800 140280725968768 learning.py:507] global step 560: loss = 2.1235 (0.665 sec/step)\n",
            "I0718 09:19:00.697830 140280725968768 learning.py:507] global step 561: loss = 2.5212 (0.702 sec/step)\n",
            "I0718 09:19:01.359235 140280725968768 learning.py:507] global step 562: loss = 2.5322 (0.660 sec/step)\n",
            "I0718 09:19:02.045174 140280725968768 learning.py:507] global step 563: loss = 2.2143 (0.684 sec/step)\n",
            "I0718 09:19:02.723935 140280725968768 learning.py:507] global step 564: loss = 3.3583 (0.677 sec/step)\n",
            "I0718 09:19:03.404906 140280725968768 learning.py:507] global step 565: loss = 3.3035 (0.679 sec/step)\n",
            "I0718 09:19:04.093820 140280725968768 learning.py:507] global step 566: loss = 3.1269 (0.687 sec/step)\n",
            "I0718 09:19:04.780295 140280725968768 learning.py:507] global step 567: loss = 2.9014 (0.684 sec/step)\n",
            "I0718 09:19:05.454425 140280725968768 learning.py:507] global step 568: loss = 3.2245 (0.672 sec/step)\n",
            "I0718 09:19:06.135611 140280725968768 learning.py:507] global step 569: loss = 3.0434 (0.679 sec/step)\n",
            "I0718 09:19:06.824344 140280725968768 learning.py:507] global step 570: loss = 3.3770 (0.687 sec/step)\n",
            "I0718 09:19:07.502821 140280725968768 learning.py:507] global step 571: loss = 2.4339 (0.677 sec/step)\n",
            "I0718 09:19:08.181376 140280725968768 learning.py:507] global step 572: loss = 3.5182 (0.676 sec/step)\n",
            "I0718 09:19:08.846556 140280725968768 learning.py:507] global step 573: loss = 2.5496 (0.663 sec/step)\n",
            "I0718 09:19:09.546379 140280725968768 learning.py:507] global step 574: loss = 2.6287 (0.698 sec/step)\n",
            "I0718 09:19:10.180374 140280725968768 learning.py:507] global step 575: loss = 2.2932 (0.632 sec/step)\n",
            "I0718 09:19:10.856695 140280725968768 learning.py:507] global step 576: loss = 2.3116 (0.674 sec/step)\n",
            "I0718 09:19:11.547425 140280725968768 learning.py:507] global step 577: loss = 2.8528 (0.689 sec/step)\n",
            "I0718 09:19:12.209596 140280725968768 learning.py:507] global step 578: loss = 3.0006 (0.660 sec/step)\n",
            "I0718 09:19:12.878304 140280725968768 learning.py:507] global step 579: loss = 3.0934 (0.667 sec/step)\n",
            "I0718 09:19:13.549409 140280725968768 learning.py:507] global step 580: loss = 2.8871 (0.669 sec/step)\n",
            "I0718 09:19:14.224625 140280725968768 learning.py:507] global step 581: loss = 3.2250 (0.673 sec/step)\n",
            "I0718 09:19:14.928769 140280725968768 learning.py:507] global step 582: loss = 3.0050 (0.702 sec/step)\n",
            "I0718 09:19:15.644740 140280725968768 learning.py:507] global step 583: loss = 2.1232 (0.714 sec/step)\n",
            "I0718 09:19:16.338261 140280725968768 learning.py:507] global step 584: loss = 2.9589 (0.692 sec/step)\n",
            "I0718 09:19:17.009429 140280725968768 learning.py:507] global step 585: loss = 3.1069 (0.669 sec/step)\n",
            "I0718 09:19:17.698325 140280725968768 learning.py:507] global step 586: loss = 2.3650 (0.687 sec/step)\n",
            "I0718 09:19:18.388912 140280725968768 learning.py:507] global step 587: loss = 2.7182 (0.689 sec/step)\n",
            "I0718 09:19:19.029491 140280725968768 learning.py:507] global step 588: loss = 2.5660 (0.639 sec/step)\n",
            "I0718 09:19:19.718472 140280725968768 learning.py:507] global step 589: loss = 2.6742 (0.687 sec/step)\n",
            "I0718 09:19:20.389065 140280725968768 learning.py:507] global step 590: loss = 2.8096 (0.668 sec/step)\n",
            "I0718 09:19:21.059825 140280725968768 learning.py:507] global step 591: loss = 3.4229 (0.669 sec/step)\n",
            "I0718 09:19:21.738682 140280725968768 learning.py:507] global step 592: loss = 2.7072 (0.677 sec/step)\n",
            "I0718 09:19:22.416533 140280725968768 learning.py:507] global step 593: loss = 2.9437 (0.676 sec/step)\n",
            "I0718 09:19:23.109559 140280725968768 learning.py:507] global step 594: loss = 3.4231 (0.691 sec/step)\n",
            "I0718 09:19:23.803926 140280725968768 learning.py:507] global step 595: loss = 2.6811 (0.692 sec/step)\n",
            "I0718 09:19:24.476734 140280725968768 learning.py:507] global step 596: loss = 2.2190 (0.671 sec/step)\n",
            "I0718 09:19:25.174621 140280725968768 learning.py:507] global step 597: loss = 2.5200 (0.696 sec/step)\n",
            "I0718 09:19:25.863753 140280725968768 learning.py:507] global step 598: loss = 2.9540 (0.687 sec/step)\n",
            "I0718 09:19:26.551067 140280725968768 learning.py:507] global step 599: loss = 2.3929 (0.685 sec/step)\n",
            "I0718 09:19:27.243872 140280725968768 learning.py:507] global step 600: loss = 3.0389 (0.691 sec/step)\n",
            "I0718 09:19:27.935740 140280725968768 learning.py:507] global step 601: loss = 2.5655 (0.690 sec/step)\n",
            "I0718 09:19:28.610230 140280725968768 learning.py:507] global step 602: loss = 2.7838 (0.673 sec/step)\n",
            "I0718 09:19:29.326754 140280725968768 learning.py:507] global step 603: loss = 3.8212 (0.715 sec/step)\n",
            "I0718 09:19:30.008635 140280725968768 learning.py:507] global step 604: loss = 2.7910 (0.680 sec/step)\n",
            "I0718 09:19:30.705369 140280725968768 learning.py:507] global step 605: loss = 2.9344 (0.694 sec/step)\n",
            "I0718 09:19:31.399479 140280725968768 learning.py:507] global step 606: loss = 2.8238 (0.691 sec/step)\n",
            "I0718 09:19:32.074541 140280725968768 learning.py:507] global step 607: loss = 2.8666 (0.673 sec/step)\n",
            "I0718 09:19:32.732706 140280725968768 learning.py:507] global step 608: loss = 2.4842 (0.656 sec/step)\n",
            "I0718 09:19:33.445634 140280725968768 learning.py:507] global step 609: loss = 2.2363 (0.711 sec/step)\n",
            "I0718 09:19:34.142297 140280725968768 learning.py:507] global step 610: loss = 3.3514 (0.695 sec/step)\n",
            "I0718 09:19:34.799233 140280725968768 learning.py:507] global step 611: loss = 3.2227 (0.655 sec/step)\n",
            "I0718 09:19:35.469918 140280725968768 learning.py:507] global step 612: loss = 3.5606 (0.669 sec/step)\n",
            "I0718 09:19:36.142281 140280725968768 learning.py:507] global step 613: loss = 2.6967 (0.671 sec/step)\n",
            "I0718 09:19:36.820472 140280725968768 learning.py:507] global step 614: loss = 2.4904 (0.676 sec/step)\n",
            "I0718 09:19:37.512684 140280725968768 learning.py:507] global step 615: loss = 2.2303 (0.691 sec/step)\n",
            "I0718 09:19:38.223878 140280725968768 learning.py:507] global step 616: loss = 2.6803 (0.709 sec/step)\n",
            "I0718 09:19:38.916855 140280725968768 learning.py:507] global step 617: loss = 2.2415 (0.691 sec/step)\n",
            "I0718 09:19:39.606701 140280725968768 learning.py:507] global step 618: loss = 3.1401 (0.688 sec/step)\n",
            "I0718 09:19:40.276958 140280725968768 learning.py:507] global step 619: loss = 2.7703 (0.668 sec/step)\n",
            "I0718 09:19:40.959445 140280725968768 learning.py:507] global step 620: loss = 2.7521 (0.680 sec/step)\n",
            "I0718 09:19:41.650558 140280725968768 learning.py:507] global step 621: loss = 2.2901 (0.689 sec/step)\n",
            "I0718 09:19:42.339902 140280725968768 learning.py:507] global step 622: loss = 2.6419 (0.687 sec/step)\n",
            "I0718 09:19:43.001132 140280725968768 learning.py:507] global step 623: loss = 3.3138 (0.659 sec/step)\n",
            "I0718 09:19:43.709115 140280725968768 learning.py:507] global step 624: loss = 3.9318 (0.706 sec/step)\n",
            "I0718 09:19:44.371793 140280725968768 learning.py:507] global step 625: loss = 3.3538 (0.661 sec/step)\n",
            "I0718 09:19:45.035478 140280725968768 learning.py:507] global step 626: loss = 2.8191 (0.662 sec/step)\n",
            "I0718 09:19:45.730737 140280725968768 learning.py:507] global step 627: loss = 2.4684 (0.693 sec/step)\n",
            "I0718 09:19:46.412082 140280725968768 learning.py:507] global step 628: loss = 2.5137 (0.680 sec/step)\n",
            "I0718 09:19:47.112819 140280725968768 learning.py:507] global step 629: loss = 1.9605 (0.699 sec/step)\n",
            "I0718 09:19:47.791059 140280725968768 learning.py:507] global step 630: loss = 2.4509 (0.677 sec/step)\n",
            "I0718 09:19:48.461064 140280725968768 learning.py:507] global step 631: loss = 2.9509 (0.668 sec/step)\n",
            "I0718 09:19:49.131291 140280725968768 learning.py:507] global step 632: loss = 3.2880 (0.668 sec/step)\n",
            "I0718 09:19:49.816620 140280725968768 learning.py:507] global step 633: loss = 3.4374 (0.684 sec/step)\n",
            "I0718 09:19:50.486873 140280725968768 learning.py:507] global step 634: loss = 2.5202 (0.668 sec/step)\n",
            "I0718 09:19:51.164388 140280725968768 learning.py:507] global step 635: loss = 2.7550 (0.676 sec/step)\n",
            "I0718 09:19:51.863541 140280725968768 learning.py:507] global step 636: loss = 3.4681 (0.697 sec/step)\n",
            "I0718 09:19:52.555600 140280725968768 learning.py:507] global step 637: loss = 2.7668 (0.690 sec/step)\n",
            "I0718 09:19:53.225964 140280725968768 learning.py:507] global step 638: loss = 3.3867 (0.668 sec/step)\n",
            "I0718 09:19:53.922209 140280725968768 learning.py:507] global step 639: loss = 2.3791 (0.693 sec/step)\n",
            "I0718 09:19:54.590344 140280725968768 learning.py:507] global step 640: loss = 3.6593 (0.666 sec/step)\n",
            "I0718 09:19:55.288590 140280725968768 learning.py:507] global step 641: loss = 2.5421 (0.696 sec/step)\n",
            "I0718 09:19:55.972604 140280725968768 learning.py:507] global step 642: loss = 3.2751 (0.682 sec/step)\n",
            "I0718 09:19:56.654538 140280725968768 learning.py:507] global step 643: loss = 2.5397 (0.680 sec/step)\n",
            "I0718 09:19:57.327393 140280725968768 learning.py:507] global step 644: loss = 2.4560 (0.671 sec/step)\n",
            "I0718 09:19:58.007900 140280725968768 learning.py:507] global step 645: loss = 2.5546 (0.679 sec/step)\n",
            "I0718 09:19:58.684603 140280725968768 learning.py:507] global step 646: loss = 2.9943 (0.675 sec/step)\n",
            "I0718 09:19:59.353375 140280725968768 learning.py:507] global step 647: loss = 2.8383 (0.667 sec/step)\n",
            "I0718 09:20:00.030580 140280725968768 learning.py:507] global step 648: loss = 3.6531 (0.675 sec/step)\n",
            "I0718 09:20:00.716990 140280725968768 learning.py:507] global step 649: loss = 2.5536 (0.685 sec/step)\n",
            "I0718 09:20:01.401361 140280725968768 learning.py:507] global step 650: loss = 2.2579 (0.683 sec/step)\n",
            "I0718 09:20:02.077362 140280725968768 learning.py:507] global step 651: loss = 2.5213 (0.674 sec/step)\n",
            "I0718 09:20:02.753142 140280725968768 learning.py:507] global step 652: loss = 2.4686 (0.673 sec/step)\n",
            "I0718 09:20:03.427201 140280725968768 learning.py:507] global step 653: loss = 2.2693 (0.672 sec/step)\n",
            "I0718 09:20:04.097976 140280725968768 learning.py:507] global step 654: loss = 2.4785 (0.669 sec/step)\n",
            "I0718 09:20:04.785412 140280725968768 learning.py:507] global step 655: loss = 3.0944 (0.685 sec/step)\n",
            "I0718 09:20:05.481291 140280725968768 learning.py:507] global step 656: loss = 3.2264 (0.694 sec/step)\n",
            "I0718 09:20:06.184780 140280725968768 learning.py:507] global step 657: loss = 3.4178 (0.702 sec/step)\n",
            "I0718 09:20:06.884233 140280725968768 learning.py:507] global step 658: loss = 3.1084 (0.698 sec/step)\n",
            "I0718 09:20:07.559284 140280725968768 learning.py:507] global step 659: loss = 2.1317 (0.671 sec/step)\n",
            "I0718 09:20:08.228466 140280725968768 learning.py:507] global step 660: loss = 2.9377 (0.667 sec/step)\n",
            "I0718 09:20:08.902763 140280725968768 learning.py:507] global step 661: loss = 2.7679 (0.672 sec/step)\n",
            "I0718 09:20:09.573445 140280725968768 learning.py:507] global step 662: loss = 2.6703 (0.668 sec/step)\n",
            "I0718 09:20:10.258039 140280725968768 learning.py:507] global step 663: loss = 2.8536 (0.683 sec/step)\n",
            "I0718 09:20:10.912920 140280725968768 learning.py:507] global step 664: loss = 3.7250 (0.653 sec/step)\n",
            "I0718 09:20:11.615355 140280725968768 learning.py:507] global step 665: loss = 2.0232 (0.701 sec/step)\n",
            "I0718 09:20:12.318496 140280725968768 learning.py:507] global step 666: loss = 3.2321 (0.701 sec/step)\n",
            "I0718 09:20:12.976830 140280725968768 learning.py:507] global step 667: loss = 2.4778 (0.656 sec/step)\n",
            "I0718 09:20:13.666750 140280725968768 learning.py:507] global step 668: loss = 2.6919 (0.688 sec/step)\n",
            "I0718 09:20:14.377956 140280725968768 learning.py:507] global step 669: loss = 2.9999 (0.709 sec/step)\n",
            "I0718 09:20:15.046325 140280725968768 learning.py:507] global step 670: loss = 2.1418 (0.666 sec/step)\n",
            "I0718 09:20:15.735016 140280725968768 learning.py:507] global step 671: loss = 3.1277 (0.687 sec/step)\n",
            "I0718 09:20:16.413609 140280725968768 learning.py:507] global step 672: loss = 2.2644 (0.677 sec/step)\n",
            "I0718 09:20:17.097282 140280725968768 learning.py:507] global step 673: loss = 2.6705 (0.682 sec/step)\n",
            "I0718 09:20:17.951001 140280725968768 learning.py:507] global step 674: loss = 3.3512 (0.847 sec/step)\n",
            "I0718 09:20:18.781329 140277976831744 supervisor.py:1050] Recording summary at step 674.\n",
            "I0718 09:20:19.035955 140280725968768 learning.py:507] global step 675: loss = 2.7242 (1.006 sec/step)\n",
            "I0718 09:20:19.716402 140280725968768 learning.py:507] global step 676: loss = 2.2963 (0.679 sec/step)\n",
            "I0718 09:20:20.134889 140279010821888 supervisor.py:1099] global_step/sec: 1.45884\n",
            "I0718 09:20:20.401993 140280725968768 learning.py:507] global step 677: loss = 2.7582 (0.684 sec/step)\n",
            "I0718 09:20:21.070939 140280725968768 learning.py:507] global step 678: loss = 2.6112 (0.667 sec/step)\n",
            "I0718 09:20:21.751657 140280725968768 learning.py:507] global step 679: loss = 2.4702 (0.679 sec/step)\n",
            "I0718 09:20:22.414395 140280725968768 learning.py:507] global step 680: loss = 4.4205 (0.661 sec/step)\n",
            "I0718 09:20:23.132481 140280725968768 learning.py:507] global step 681: loss = 2.4019 (0.716 sec/step)\n",
            "I0718 09:20:23.809639 140280725968768 learning.py:507] global step 682: loss = 2.3630 (0.675 sec/step)\n",
            "I0718 09:20:24.529634 140280725968768 learning.py:507] global step 683: loss = 3.3671 (0.718 sec/step)\n",
            "I0718 09:20:25.184050 140280725968768 learning.py:507] global step 684: loss = 3.2417 (0.653 sec/step)\n",
            "I0718 09:20:25.877546 140280725968768 learning.py:507] global step 685: loss = 3.1249 (0.692 sec/step)\n",
            "I0718 09:20:26.560604 140280725968768 learning.py:507] global step 686: loss = 2.5663 (0.681 sec/step)\n",
            "I0718 09:20:27.270800 140280725968768 learning.py:507] global step 687: loss = 2.1774 (0.708 sec/step)\n",
            "I0718 09:20:27.947834 140280725968768 learning.py:507] global step 688: loss = 3.0731 (0.675 sec/step)\n",
            "I0718 09:20:28.631468 140280725968768 learning.py:507] global step 689: loss = 3.2621 (0.682 sec/step)\n",
            "I0718 09:20:29.312573 140280725968768 learning.py:507] global step 690: loss = 2.7508 (0.679 sec/step)\n",
            "I0718 09:20:29.991967 140280725968768 learning.py:507] global step 691: loss = 2.6915 (0.678 sec/step)\n",
            "I0718 09:20:30.659356 140280725968768 learning.py:507] global step 692: loss = 2.5078 (0.665 sec/step)\n",
            "I0718 09:20:31.323514 140280725968768 learning.py:507] global step 693: loss = 2.4800 (0.663 sec/step)\n",
            "I0718 09:20:31.985821 140280725968768 learning.py:507] global step 694: loss = 2.2517 (0.660 sec/step)\n",
            "I0718 09:20:32.659970 140280725968768 learning.py:507] global step 695: loss = 2.2750 (0.673 sec/step)\n",
            "I0718 09:20:33.329653 140280725968768 learning.py:507] global step 696: loss = 2.9034 (0.668 sec/step)\n",
            "I0718 09:20:34.016625 140280725968768 learning.py:507] global step 697: loss = 3.5424 (0.685 sec/step)\n",
            "I0718 09:20:34.694176 140280725968768 learning.py:507] global step 698: loss = 2.7415 (0.675 sec/step)\n",
            "I0718 09:20:35.388626 140280725968768 learning.py:507] global step 699: loss = 3.0932 (0.692 sec/step)\n",
            "I0718 09:20:36.074774 140280725968768 learning.py:507] global step 700: loss = 2.4846 (0.684 sec/step)\n",
            "I0718 09:20:36.763436 140280725968768 learning.py:507] global step 701: loss = 2.9859 (0.687 sec/step)\n",
            "I0718 09:20:37.483008 140280725968768 learning.py:507] global step 702: loss = 2.2360 (0.718 sec/step)\n",
            "I0718 09:20:38.162621 140280725968768 learning.py:507] global step 703: loss = 3.2064 (0.678 sec/step)\n",
            "I0718 09:20:38.818609 140280725968768 learning.py:507] global step 704: loss = 2.3949 (0.654 sec/step)\n",
            "I0718 09:20:39.499001 140280725968768 learning.py:507] global step 705: loss = 2.6446 (0.678 sec/step)\n",
            "I0718 09:20:40.187141 140280725968768 learning.py:507] global step 706: loss = 2.7742 (0.686 sec/step)\n",
            "I0718 09:20:40.866474 140280725968768 learning.py:507] global step 707: loss = 3.7922 (0.677 sec/step)\n",
            "I0718 09:20:41.552194 140280725968768 learning.py:507] global step 708: loss = 2.3377 (0.684 sec/step)\n",
            "I0718 09:20:42.227705 140280725968768 learning.py:507] global step 709: loss = 2.7177 (0.674 sec/step)\n",
            "I0718 09:20:42.915099 140280725968768 learning.py:507] global step 710: loss = 2.2729 (0.686 sec/step)\n",
            "I0718 09:20:43.616501 140280725968768 learning.py:507] global step 711: loss = 2.3516 (0.699 sec/step)\n",
            "I0718 09:20:44.293230 140280725968768 learning.py:507] global step 712: loss = 2.6150 (0.675 sec/step)\n",
            "I0718 09:20:44.983142 140280725968768 learning.py:507] global step 713: loss = 3.2802 (0.688 sec/step)\n",
            "I0718 09:20:45.718727 140280725968768 learning.py:507] global step 714: loss = 3.1962 (0.733 sec/step)\n",
            "I0718 09:20:46.419786 140280725968768 learning.py:507] global step 715: loss = 2.6229 (0.699 sec/step)\n",
            "I0718 09:20:47.096343 140280725968768 learning.py:507] global step 716: loss = 2.1310 (0.675 sec/step)\n",
            "I0718 09:20:47.776701 140280725968768 learning.py:507] global step 717: loss = 3.0361 (0.679 sec/step)\n",
            "I0718 09:20:48.452555 140280725968768 learning.py:507] global step 718: loss = 3.6436 (0.674 sec/step)\n",
            "I0718 09:20:49.122578 140280725968768 learning.py:507] global step 719: loss = 2.2506 (0.668 sec/step)\n",
            "I0718 09:20:49.796651 140280725968768 learning.py:507] global step 720: loss = 2.6519 (0.672 sec/step)\n",
            "I0718 09:20:50.465914 140280725968768 learning.py:507] global step 721: loss = 3.0341 (0.667 sec/step)\n",
            "I0718 09:20:51.141714 140280725968768 learning.py:507] global step 722: loss = 2.3467 (0.674 sec/step)\n",
            "I0718 09:20:51.834881 140280725968768 learning.py:507] global step 723: loss = 2.7331 (0.692 sec/step)\n",
            "I0718 09:20:52.520801 140280725968768 learning.py:507] global step 724: loss = 2.1146 (0.684 sec/step)\n",
            "I0718 09:20:53.198243 140280725968768 learning.py:507] global step 725: loss = 2.9051 (0.676 sec/step)\n",
            "I0718 09:20:53.901488 140280725968768 learning.py:507] global step 726: loss = 2.0045 (0.701 sec/step)\n",
            "I0718 09:20:54.570421 140280725968768 learning.py:507] global step 727: loss = 2.4968 (0.667 sec/step)\n",
            "I0718 09:20:55.265985 140280725968768 learning.py:507] global step 728: loss = 2.7121 (0.694 sec/step)\n",
            "I0718 09:20:55.983488 140280725968768 learning.py:507] global step 729: loss = 2.5784 (0.716 sec/step)\n",
            "I0718 09:20:56.672957 140280725968768 learning.py:507] global step 730: loss = 3.0791 (0.688 sec/step)\n",
            "I0718 09:20:57.362601 140280725968768 learning.py:507] global step 731: loss = 2.4970 (0.688 sec/step)\n",
            "I0718 09:20:58.081707 140280725968768 learning.py:507] global step 732: loss = 3.0990 (0.717 sec/step)\n",
            "I0718 09:20:58.767248 140280725968768 learning.py:507] global step 733: loss = 2.2351 (0.684 sec/step)\n",
            "I0718 09:20:59.448928 140280725968768 learning.py:507] global step 734: loss = 3.0504 (0.680 sec/step)\n",
            "I0718 09:21:00.152741 140280725968768 learning.py:507] global step 735: loss = 2.5768 (0.702 sec/step)\n",
            "I0718 09:21:00.849560 140280725968768 learning.py:507] global step 736: loss = 2.0353 (0.695 sec/step)\n",
            "I0718 09:21:01.502287 140280725968768 learning.py:507] global step 737: loss = 2.5335 (0.651 sec/step)\n",
            "I0718 09:21:02.179783 140280725968768 learning.py:507] global step 738: loss = 2.4817 (0.675 sec/step)\n",
            "I0718 09:21:02.872839 140280725968768 learning.py:507] global step 739: loss = 3.0557 (0.691 sec/step)\n",
            "I0718 09:21:03.541476 140280725968768 learning.py:507] global step 740: loss = 2.0801 (0.667 sec/step)\n",
            "I0718 09:21:04.235774 140280725968768 learning.py:507] global step 741: loss = 3.4763 (0.692 sec/step)\n",
            "I0718 09:21:04.921896 140280725968768 learning.py:507] global step 742: loss = 2.6093 (0.684 sec/step)\n",
            "I0718 09:21:05.599638 140280725968768 learning.py:507] global step 743: loss = 3.0508 (0.676 sec/step)\n",
            "I0718 09:21:06.278025 140280725968768 learning.py:507] global step 744: loss = 2.0318 (0.676 sec/step)\n",
            "I0718 09:21:06.962690 140280725968768 learning.py:507] global step 745: loss = 2.8828 (0.683 sec/step)\n",
            "I0718 09:21:07.662754 140280725968768 learning.py:507] global step 746: loss = 3.3341 (0.698 sec/step)\n",
            "I0718 09:21:08.325792 140280725968768 learning.py:507] global step 747: loss = 2.8452 (0.661 sec/step)\n",
            "I0718 09:21:09.001643 140280725968768 learning.py:507] global step 748: loss = 3.6204 (0.674 sec/step)\n",
            "I0718 09:21:09.639460 140280725968768 learning.py:507] global step 749: loss = 3.1056 (0.636 sec/step)\n",
            "I0718 09:21:10.314187 140280725968768 learning.py:507] global step 750: loss = 2.7447 (0.673 sec/step)\n",
            "I0718 09:21:10.977173 140280725968768 learning.py:507] global step 751: loss = 2.4719 (0.661 sec/step)\n",
            "I0718 09:21:11.647755 140280725968768 learning.py:507] global step 752: loss = 2.7770 (0.669 sec/step)\n",
            "I0718 09:21:12.330195 140280725968768 learning.py:507] global step 753: loss = 3.1207 (0.681 sec/step)\n",
            "I0718 09:21:12.975536 140280725968768 learning.py:507] global step 754: loss = 3.1062 (0.644 sec/step)\n",
            "I0718 09:21:13.630457 140280725968768 learning.py:507] global step 755: loss = 2.5774 (0.653 sec/step)\n",
            "I0718 09:21:14.305507 140280725968768 learning.py:507] global step 756: loss = 2.2959 (0.673 sec/step)\n",
            "I0718 09:21:14.978283 140280725968768 learning.py:507] global step 757: loss = 2.7428 (0.671 sec/step)\n",
            "I0718 09:21:15.629339 140280725968768 learning.py:507] global step 758: loss = 2.2518 (0.649 sec/step)\n",
            "I0718 09:21:16.288815 140280725968768 learning.py:507] global step 759: loss = 2.3438 (0.658 sec/step)\n",
            "I0718 09:21:16.939320 140280725968768 learning.py:507] global step 760: loss = 2.4630 (0.649 sec/step)\n",
            "I0718 09:21:17.630651 140280725968768 learning.py:507] global step 761: loss = 3.7910 (0.690 sec/step)\n",
            "I0718 09:21:18.273562 140280725968768 learning.py:507] global step 762: loss = 3.1700 (0.641 sec/step)\n",
            "I0718 09:21:18.962284 140280725968768 learning.py:507] global step 763: loss = 2.5017 (0.687 sec/step)\n",
            "I0718 09:21:19.635510 140280725968768 learning.py:507] global step 764: loss = 2.5153 (0.672 sec/step)\n",
            "I0718 09:21:20.301230 140280725968768 learning.py:507] global step 765: loss = 3.2054 (0.663 sec/step)\n",
            "I0718 09:21:20.963773 140280725968768 learning.py:507] global step 766: loss = 2.7393 (0.661 sec/step)\n",
            "I0718 09:21:21.625039 140280725968768 learning.py:507] global step 767: loss = 2.1800 (0.659 sec/step)\n",
            "I0718 09:21:22.297032 140280725968768 learning.py:507] global step 768: loss = 2.4126 (0.670 sec/step)\n",
            "I0718 09:21:22.961830 140280725968768 learning.py:507] global step 769: loss = 2.5977 (0.663 sec/step)\n",
            "I0718 09:21:23.675904 140280725968768 learning.py:507] global step 770: loss = 2.8950 (0.712 sec/step)\n",
            "I0718 09:21:24.354386 140280725968768 learning.py:507] global step 771: loss = 2.7193 (0.677 sec/step)\n",
            "I0718 09:21:25.039201 140280725968768 learning.py:507] global step 772: loss = 2.8482 (0.682 sec/step)\n",
            "I0718 09:21:25.723958 140280725968768 learning.py:507] global step 773: loss = 2.5039 (0.683 sec/step)\n",
            "I0718 09:21:26.415554 140280725968768 learning.py:507] global step 774: loss = 3.3637 (0.690 sec/step)\n",
            "I0718 09:21:27.090533 140280725968768 learning.py:507] global step 775: loss = 3.4762 (0.673 sec/step)\n",
            "I0718 09:21:27.784622 140280725968768 learning.py:507] global step 776: loss = 2.3524 (0.692 sec/step)\n",
            "I0718 09:21:28.441050 140280725968768 learning.py:507] global step 777: loss = 2.3722 (0.655 sec/step)\n",
            "I0718 09:21:29.125141 140280725968768 learning.py:507] global step 778: loss = 2.3637 (0.682 sec/step)\n",
            "I0718 09:21:29.865885 140280725968768 learning.py:507] global step 779: loss = 2.4833 (0.739 sec/step)\n",
            "I0718 09:21:30.520729 140280725968768 learning.py:507] global step 780: loss = 4.1063 (0.653 sec/step)\n",
            "I0718 09:21:31.180788 140280725968768 learning.py:507] global step 781: loss = 2.6700 (0.658 sec/step)\n",
            "I0718 09:21:31.868355 140280725968768 learning.py:507] global step 782: loss = 2.3833 (0.686 sec/step)\n",
            "I0718 09:21:32.531751 140280725968768 learning.py:507] global step 783: loss = 2.1809 (0.661 sec/step)\n",
            "I0718 09:21:33.176320 140280725968768 learning.py:507] global step 784: loss = 3.6790 (0.643 sec/step)\n",
            "I0718 09:21:33.828163 140280725968768 learning.py:507] global step 785: loss = 3.4899 (0.650 sec/step)\n",
            "I0718 09:21:34.502514 140280725968768 learning.py:507] global step 786: loss = 2.3466 (0.672 sec/step)\n",
            "I0718 09:21:35.188691 140280725968768 learning.py:507] global step 787: loss = 1.9192 (0.684 sec/step)\n",
            "I0718 09:21:35.851895 140280725968768 learning.py:507] global step 788: loss = 3.3841 (0.661 sec/step)\n",
            "I0718 09:21:36.511891 140280725968768 learning.py:507] global step 789: loss = 2.9622 (0.658 sec/step)\n",
            "I0718 09:21:37.204251 140280725968768 learning.py:507] global step 790: loss = 2.6786 (0.691 sec/step)\n",
            "I0718 09:21:37.844049 140280725968768 learning.py:507] global step 791: loss = 3.2749 (0.638 sec/step)\n",
            "I0718 09:21:38.513047 140280725968768 learning.py:507] global step 792: loss = 4.1396 (0.667 sec/step)\n",
            "I0718 09:21:39.169306 140280725968768 learning.py:507] global step 793: loss = 2.8941 (0.655 sec/step)\n",
            "I0718 09:21:39.840191 140280725968768 learning.py:507] global step 794: loss = 2.7248 (0.669 sec/step)\n",
            "I0718 09:21:40.518899 140280725968768 learning.py:507] global step 795: loss = 2.4576 (0.677 sec/step)\n",
            "I0718 09:21:41.209868 140280725968768 learning.py:507] global step 796: loss = 2.4022 (0.689 sec/step)\n",
            "I0718 09:21:41.877060 140280725968768 learning.py:507] global step 797: loss = 3.2008 (0.665 sec/step)\n",
            "I0718 09:21:42.539595 140280725968768 learning.py:507] global step 798: loss = 2.3047 (0.661 sec/step)\n",
            "I0718 09:21:43.213733 140280725968768 learning.py:507] global step 799: loss = 3.2455 (0.672 sec/step)\n",
            "I0718 09:21:43.868207 140280725968768 learning.py:507] global step 800: loss = 2.2305 (0.653 sec/step)\n",
            "I0718 09:21:44.530808 140280725968768 learning.py:507] global step 801: loss = 2.4917 (0.660 sec/step)\n",
            "I0718 09:21:45.221172 140280725968768 learning.py:507] global step 802: loss = 2.6406 (0.689 sec/step)\n",
            "I0718 09:21:45.933860 140280725968768 learning.py:507] global step 803: loss = 2.3953 (0.710 sec/step)\n",
            "I0718 09:21:46.601520 140280725968768 learning.py:507] global step 804: loss = 2.8264 (0.666 sec/step)\n",
            "I0718 09:21:47.282877 140280725968768 learning.py:507] global step 805: loss = 3.3742 (0.680 sec/step)\n",
            "I0718 09:21:47.944901 140280725968768 learning.py:507] global step 806: loss = 2.1050 (0.660 sec/step)\n",
            "I0718 09:21:48.614810 140280725968768 learning.py:507] global step 807: loss = 2.7119 (0.668 sec/step)\n",
            "I0718 09:21:49.291822 140280725968768 learning.py:507] global step 808: loss = 2.5649 (0.675 sec/step)\n",
            "I0718 09:21:49.995444 140280725968768 learning.py:507] global step 809: loss = 3.1533 (0.702 sec/step)\n",
            "I0718 09:21:50.662848 140280725968768 learning.py:507] global step 810: loss = 3.0702 (0.666 sec/step)\n",
            "I0718 09:21:51.346232 140280725968768 learning.py:507] global step 811: loss = 4.2177 (0.682 sec/step)\n",
            "I0718 09:21:52.060834 140280725968768 learning.py:507] global step 812: loss = 2.7869 (0.713 sec/step)\n",
            "I0718 09:21:52.733710 140280725968768 learning.py:507] global step 813: loss = 2.7625 (0.671 sec/step)\n",
            "I0718 09:21:53.418242 140280725968768 learning.py:507] global step 814: loss = 2.7714 (0.683 sec/step)\n",
            "I0718 09:21:54.099176 140280725968768 learning.py:507] global step 815: loss = 3.1502 (0.679 sec/step)\n",
            "I0718 09:21:54.801791 140280725968768 learning.py:507] global step 816: loss = 2.6495 (0.701 sec/step)\n",
            "I0718 09:21:55.486000 140280725968768 learning.py:507] global step 817: loss = 2.6766 (0.683 sec/step)\n",
            "I0718 09:21:56.170223 140280725968768 learning.py:507] global step 818: loss = 3.2295 (0.682 sec/step)\n",
            "I0718 09:21:56.843104 140280725968768 learning.py:507] global step 819: loss = 2.0371 (0.671 sec/step)\n",
            "I0718 09:21:57.536954 140280725968768 learning.py:507] global step 820: loss = 2.1299 (0.692 sec/step)\n",
            "I0718 09:21:58.220648 140280725968768 learning.py:507] global step 821: loss = 2.6078 (0.682 sec/step)\n",
            "I0718 09:21:58.885923 140280725968768 learning.py:507] global step 822: loss = 2.1356 (0.663 sec/step)\n",
            "I0718 09:21:59.551800 140280725968768 learning.py:507] global step 823: loss = 2.9735 (0.664 sec/step)\n",
            "I0718 09:22:00.246270 140280725968768 learning.py:507] global step 824: loss = 2.5742 (0.693 sec/step)\n",
            "I0718 09:22:00.912095 140280725968768 learning.py:507] global step 825: loss = 2.4261 (0.664 sec/step)\n",
            "I0718 09:22:01.593921 140280725968768 learning.py:507] global step 826: loss = 3.8889 (0.680 sec/step)\n",
            "I0718 09:22:02.248176 140280725968768 learning.py:507] global step 827: loss = 3.8923 (0.652 sec/step)\n",
            "I0718 09:22:02.935065 140280725968768 learning.py:507] global step 828: loss = 3.5593 (0.685 sec/step)\n",
            "I0718 09:22:03.595220 140280725968768 learning.py:507] global step 829: loss = 2.3477 (0.659 sec/step)\n",
            "I0718 09:22:04.251272 140280725968768 learning.py:507] global step 830: loss = 2.6647 (0.654 sec/step)\n",
            "I0718 09:22:04.938326 140280725968768 learning.py:507] global step 831: loss = 2.7909 (0.685 sec/step)\n",
            "I0718 09:22:05.598345 140280725968768 learning.py:507] global step 832: loss = 2.1831 (0.658 sec/step)\n",
            "I0718 09:22:06.263180 140280725968768 learning.py:507] global step 833: loss = 3.5692 (0.663 sec/step)\n",
            "I0718 09:22:06.918884 140280725968768 learning.py:507] global step 834: loss = 2.3799 (0.654 sec/step)\n",
            "I0718 09:22:07.603362 140280725968768 learning.py:507] global step 835: loss = 4.3955 (0.683 sec/step)\n",
            "I0718 09:22:08.260800 140280725968768 learning.py:507] global step 836: loss = 2.8970 (0.656 sec/step)\n",
            "I0718 09:22:08.928440 140280725968768 learning.py:507] global step 837: loss = 2.9474 (0.666 sec/step)\n",
            "I0718 09:22:09.608095 140280725968768 learning.py:507] global step 838: loss = 2.2019 (0.678 sec/step)\n",
            "I0718 09:22:10.265547 140280725968768 learning.py:507] global step 839: loss = 3.4644 (0.656 sec/step)\n",
            "I0718 09:22:10.934789 140280725968768 learning.py:507] global step 840: loss = 3.4290 (0.668 sec/step)\n",
            "I0718 09:22:11.648386 140280725968768 learning.py:507] global step 841: loss = 1.8758 (0.712 sec/step)\n",
            "I0718 09:22:12.340240 140280725968768 learning.py:507] global step 842: loss = 4.2071 (0.690 sec/step)\n",
            "I0718 09:22:12.994120 140280725968768 learning.py:507] global step 843: loss = 3.3315 (0.652 sec/step)\n",
            "I0718 09:22:13.662994 140280725968768 learning.py:507] global step 844: loss = 1.9922 (0.667 sec/step)\n",
            "I0718 09:22:14.369263 140280725968768 learning.py:507] global step 845: loss = 2.7813 (0.705 sec/step)\n",
            "I0718 09:22:15.048255 140280725968768 learning.py:507] global step 846: loss = 2.4966 (0.677 sec/step)\n",
            "I0718 09:22:15.737433 140280725968768 learning.py:507] global step 847: loss = 2.5593 (0.687 sec/step)\n",
            "I0718 09:22:16.427409 140280725968768 learning.py:507] global step 848: loss = 2.4547 (0.688 sec/step)\n",
            "I0718 09:22:17.104798 140280725968768 learning.py:507] global step 849: loss = 2.2228 (0.676 sec/step)\n",
            "I0718 09:22:17.408633 140279019214592 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n",
            "I0718 09:22:18.812253 140277976831744 supervisor.py:1050] Recording summary at step 850.\n",
            "I0718 09:22:18.812709 140280725968768 learning.py:507] global step 850: loss = 2.3445 (1.700 sec/step)\n",
            "I0718 09:22:19.814780 140280725968768 learning.py:507] global step 851: loss = 2.6810 (0.974 sec/step)\n",
            "I0718 09:22:20.809675 140279010821888 supervisor.py:1099] global_step/sec: 1.45018\n",
            "I0718 09:22:20.897799 140280725968768 learning.py:507] global step 852: loss = 4.4757 (1.059 sec/step)\n",
            "I0718 09:22:21.810763 140280725968768 learning.py:507] global step 853: loss = 2.0007 (0.895 sec/step)\n",
            "I0718 09:22:22.850926 140280725968768 learning.py:507] global step 854: loss = 2.5181 (0.782 sec/step)\n",
            "I0718 09:22:23.534930 140280725968768 learning.py:507] global step 855: loss = 3.0560 (0.682 sec/step)\n",
            "I0718 09:22:24.216102 140280725968768 learning.py:507] global step 856: loss = 2.3946 (0.679 sec/step)\n",
            "I0718 09:22:24.885101 140280725968768 learning.py:507] global step 857: loss = 2.8551 (0.667 sec/step)\n",
            "I0718 09:22:25.601517 140280725968768 learning.py:507] global step 858: loss = 2.3062 (0.714 sec/step)\n",
            "I0718 09:22:26.381289 140280725968768 learning.py:507] global step 859: loss = 2.1975 (0.778 sec/step)\n",
            "I0718 09:22:27.113283 140280725968768 learning.py:507] global step 860: loss = 2.3041 (0.730 sec/step)\n",
            "I0718 09:22:27.796577 140280725968768 learning.py:507] global step 861: loss = 2.4837 (0.681 sec/step)\n",
            "I0718 09:22:28.507767 140280725968768 learning.py:507] global step 862: loss = 3.3482 (0.709 sec/step)\n",
            "I0718 09:22:29.214495 140280725968768 learning.py:507] global step 863: loss = 2.4189 (0.705 sec/step)\n",
            "I0718 09:22:29.903593 140280725968768 learning.py:507] global step 864: loss = 2.1613 (0.687 sec/step)\n",
            "I0718 09:22:30.561098 140280725968768 learning.py:507] global step 865: loss = 1.8257 (0.656 sec/step)\n",
            "I0718 09:22:31.218983 140280725968768 learning.py:507] global step 866: loss = 3.6834 (0.656 sec/step)\n",
            "I0718 09:22:31.894381 140280725968768 learning.py:507] global step 867: loss = 2.0582 (0.673 sec/step)\n",
            "I0718 09:22:32.584363 140280725968768 learning.py:507] global step 868: loss = 2.3673 (0.688 sec/step)\n",
            "I0718 09:22:33.246883 140280725968768 learning.py:507] global step 869: loss = 2.0132 (0.661 sec/step)\n",
            "I0718 09:22:33.932698 140280725968768 learning.py:507] global step 870: loss = 2.5734 (0.684 sec/step)\n",
            "I0718 09:22:34.605687 140280725968768 learning.py:507] global step 871: loss = 2.1578 (0.671 sec/step)\n",
            "I0718 09:22:35.271958 140280725968768 learning.py:507] global step 872: loss = 2.4546 (0.664 sec/step)\n",
            "I0718 09:22:35.933593 140280725968768 learning.py:507] global step 873: loss = 2.2683 (0.660 sec/step)\n",
            "I0718 09:22:36.610197 140280725968768 learning.py:507] global step 874: loss = 1.9719 (0.675 sec/step)\n",
            "I0718 09:22:37.275489 140280725968768 learning.py:507] global step 875: loss = 2.8466 (0.663 sec/step)\n",
            "I0718 09:22:37.937598 140280725968768 learning.py:507] global step 876: loss = 2.2153 (0.660 sec/step)\n",
            "I0718 09:22:38.641113 140280725968768 learning.py:507] global step 877: loss = 3.8714 (0.701 sec/step)\n",
            "I0718 09:22:39.313532 140280725968768 learning.py:507] global step 878: loss = 2.3525 (0.671 sec/step)\n",
            "I0718 09:22:39.991637 140280725968768 learning.py:507] global step 879: loss = 2.3400 (0.676 sec/step)\n",
            "I0718 09:22:40.646425 140280725968768 learning.py:507] global step 880: loss = 2.8721 (0.653 sec/step)\n",
            "I0718 09:22:41.327278 140280725968768 learning.py:507] global step 881: loss = 3.0599 (0.679 sec/step)\n",
            "I0718 09:22:41.994565 140280725968768 learning.py:507] global step 882: loss = 2.4498 (0.665 sec/step)\n",
            "I0718 09:22:42.684545 140280725968768 learning.py:507] global step 883: loss = 3.1772 (0.688 sec/step)\n",
            "I0718 09:22:43.369280 140280725968768 learning.py:507] global step 884: loss = 3.1212 (0.683 sec/step)\n",
            "I0718 09:22:44.020359 140280725968768 learning.py:507] global step 885: loss = 3.1007 (0.649 sec/step)\n",
            "I0718 09:22:44.701099 140280725968768 learning.py:507] global step 886: loss = 2.2596 (0.679 sec/step)\n",
            "I0718 09:22:45.384320 140280725968768 learning.py:507] global step 887: loss = 2.9552 (0.681 sec/step)\n",
            "I0718 09:22:46.065092 140280725968768 learning.py:507] global step 888: loss = 3.2451 (0.679 sec/step)\n",
            "I0718 09:22:46.761092 140280725968768 learning.py:507] global step 889: loss = 2.2854 (0.694 sec/step)\n",
            "I0718 09:22:47.461986 140280725968768 learning.py:507] global step 890: loss = 2.3594 (0.699 sec/step)\n",
            "I0718 09:22:48.125277 140280725968768 learning.py:507] global step 891: loss = 2.5722 (0.661 sec/step)\n",
            "I0718 09:22:48.792354 140280725968768 learning.py:507] global step 892: loss = 2.5124 (0.665 sec/step)\n",
            "I0718 09:22:49.470401 140280725968768 learning.py:507] global step 893: loss = 2.6705 (0.676 sec/step)\n",
            "I0718 09:22:50.125413 140280725968768 learning.py:507] global step 894: loss = 2.0403 (0.653 sec/step)\n",
            "I0718 09:22:50.780127 140280725968768 learning.py:507] global step 895: loss = 2.4233 (0.653 sec/step)\n",
            "I0718 09:22:51.474747 140280725968768 learning.py:507] global step 896: loss = 2.0688 (0.693 sec/step)\n",
            "I0718 09:22:52.133781 140280725968768 learning.py:507] global step 897: loss = 3.3235 (0.657 sec/step)\n",
            "I0718 09:22:52.834900 140280725968768 learning.py:507] global step 898: loss = 2.9863 (0.699 sec/step)\n",
            "I0718 09:22:53.501631 140280725968768 learning.py:507] global step 899: loss = 2.1310 (0.665 sec/step)\n",
            "I0718 09:22:54.156520 140280725968768 learning.py:507] global step 900: loss = 2.6695 (0.653 sec/step)\n",
            "I0718 09:22:54.832092 140280725968768 learning.py:507] global step 901: loss = 2.0546 (0.674 sec/step)\n",
            "I0718 09:22:55.510840 140280725968768 learning.py:507] global step 902: loss = 2.1171 (0.677 sec/step)\n",
            "I0718 09:22:56.173145 140280725968768 learning.py:507] global step 903: loss = 3.1588 (0.659 sec/step)\n",
            "I0718 09:22:56.830913 140280725968768 learning.py:507] global step 904: loss = 2.4699 (0.655 sec/step)\n",
            "I0718 09:22:57.519607 140280725968768 learning.py:507] global step 905: loss = 1.8495 (0.687 sec/step)\n",
            "I0718 09:22:58.191948 140280725968768 learning.py:507] global step 906: loss = 2.6344 (0.670 sec/step)\n",
            "I0718 09:22:58.871076 140280725968768 learning.py:507] global step 907: loss = 2.9472 (0.677 sec/step)\n",
            "I0718 09:22:59.553452 140280725968768 learning.py:507] global step 908: loss = 2.6099 (0.681 sec/step)\n",
            "I0718 09:23:00.238430 140280725968768 learning.py:507] global step 909: loss = 2.5817 (0.683 sec/step)\n",
            "I0718 09:23:00.903477 140280725968768 learning.py:507] global step 910: loss = 2.8180 (0.663 sec/step)\n",
            "I0718 09:23:01.582221 140280725968768 learning.py:507] global step 911: loss = 2.7865 (0.677 sec/step)\n",
            "I0718 09:23:02.250093 140280725968768 learning.py:507] global step 912: loss = 2.5163 (0.666 sec/step)\n",
            "I0718 09:23:02.945995 140280725968768 learning.py:507] global step 913: loss = 2.4177 (0.694 sec/step)\n",
            "I0718 09:23:03.649395 140280725968768 learning.py:507] global step 914: loss = 3.2090 (0.701 sec/step)\n",
            "I0718 09:23:04.322739 140280725968768 learning.py:507] global step 915: loss = 3.0255 (0.672 sec/step)\n",
            "I0718 09:23:04.983165 140280725968768 learning.py:507] global step 916: loss = 2.8499 (0.659 sec/step)\n",
            "I0718 09:23:05.675772 140280725968768 learning.py:507] global step 917: loss = 2.4725 (0.691 sec/step)\n",
            "I0718 09:23:06.318294 140280725968768 learning.py:507] global step 918: loss = 2.0579 (0.641 sec/step)\n",
            "I0718 09:23:07.002656 140280725968768 learning.py:507] global step 919: loss = 2.2705 (0.682 sec/step)\n",
            "I0718 09:23:07.669471 140280725968768 learning.py:507] global step 920: loss = 2.3982 (0.665 sec/step)\n",
            "I0718 09:23:08.316418 140280725968768 learning.py:507] global step 921: loss = 2.9305 (0.645 sec/step)\n",
            "I0718 09:23:09.010132 140280725968768 learning.py:507] global step 922: loss = 2.2154 (0.692 sec/step)\n",
            "I0718 09:23:09.649140 140280725968768 learning.py:507] global step 923: loss = 3.4458 (0.637 sec/step)\n",
            "I0718 09:23:10.309894 140280725968768 learning.py:507] global step 924: loss = 2.0287 (0.659 sec/step)\n",
            "I0718 09:23:10.967151 140280725968768 learning.py:507] global step 925: loss = 2.4838 (0.656 sec/step)\n",
            "I0718 09:23:11.615214 140280725968768 learning.py:507] global step 926: loss = 2.1061 (0.646 sec/step)\n",
            "I0718 09:23:12.288362 140280725968768 learning.py:507] global step 927: loss = 3.4700 (0.671 sec/step)\n",
            "I0718 09:23:12.982974 140280725968768 learning.py:507] global step 928: loss = 3.7355 (0.693 sec/step)\n",
            "I0718 09:23:13.655823 140280725968768 learning.py:507] global step 929: loss = 2.9128 (0.671 sec/step)\n",
            "I0718 09:23:14.341599 140280725968768 learning.py:507] global step 930: loss = 2.5221 (0.684 sec/step)\n",
            "I0718 09:23:15.037141 140280725968768 learning.py:507] global step 931: loss = 3.3165 (0.694 sec/step)\n",
            "I0718 09:23:15.709535 140280725968768 learning.py:507] global step 932: loss = 2.6701 (0.671 sec/step)\n",
            "I0718 09:23:16.361108 140280725968768 learning.py:507] global step 933: loss = 3.0128 (0.649 sec/step)\n",
            "I0718 09:23:17.081147 140280725968768 learning.py:507] global step 934: loss = 2.5264 (0.718 sec/step)\n",
            "I0718 09:23:17.751965 140280725968768 learning.py:507] global step 935: loss = 2.2303 (0.669 sec/step)\n",
            "I0718 09:23:18.466987 140280725968768 learning.py:507] global step 936: loss = 2.3934 (0.713 sec/step)\n",
            "I0718 09:23:19.186516 140280725968768 learning.py:507] global step 937: loss = 3.2722 (0.717 sec/step)\n",
            "I0718 09:23:19.984377 140280725968768 learning.py:507] global step 938: loss = 1.7722 (0.795 sec/step)\n",
            "I0718 09:23:20.770114 140280725968768 learning.py:507] global step 939: loss = 3.5149 (0.783 sec/step)\n",
            "I0718 09:23:21.450709 140280725968768 learning.py:507] global step 940: loss = 2.9572 (0.679 sec/step)\n",
            "I0718 09:23:22.137654 140280725968768 learning.py:507] global step 941: loss = 2.5232 (0.685 sec/step)\n",
            "I0718 09:23:22.822207 140280725968768 learning.py:507] global step 942: loss = 2.6591 (0.683 sec/step)\n",
            "I0718 09:23:23.525004 140280725968768 learning.py:507] global step 943: loss = 2.7940 (0.701 sec/step)\n",
            "I0718 09:23:24.175570 140280725968768 learning.py:507] global step 944: loss = 2.1221 (0.649 sec/step)\n",
            "I0718 09:23:24.803077 140280725968768 learning.py:507] global step 945: loss = 2.2419 (0.626 sec/step)\n",
            "I0718 09:23:25.497190 140280725968768 learning.py:507] global step 946: loss = 2.0423 (0.693 sec/step)\n",
            "I0718 09:23:26.158743 140280725968768 learning.py:507] global step 947: loss = 2.6483 (0.660 sec/step)\n",
            "I0718 09:23:26.829465 140280725968768 learning.py:507] global step 948: loss = 2.2723 (0.669 sec/step)\n",
            "I0718 09:23:27.525899 140280725968768 learning.py:507] global step 949: loss = 1.9303 (0.695 sec/step)\n",
            "I0718 09:23:28.168760 140280725968768 learning.py:507] global step 950: loss = 3.3638 (0.641 sec/step)\n",
            "I0718 09:23:28.846982 140280725968768 learning.py:507] global step 951: loss = 2.3469 (0.677 sec/step)\n",
            "I0718 09:23:29.553848 140280725968768 learning.py:507] global step 952: loss = 2.8157 (0.705 sec/step)\n",
            "I0718 09:23:30.236011 140280725968768 learning.py:507] global step 953: loss = 3.6943 (0.680 sec/step)\n",
            "I0718 09:23:30.918222 140280725968768 learning.py:507] global step 954: loss = 2.9388 (0.680 sec/step)\n",
            "I0718 09:23:31.595694 140280725968768 learning.py:507] global step 955: loss = 2.9764 (0.676 sec/step)\n",
            "I0718 09:23:32.304507 140280725968768 learning.py:507] global step 956: loss = 2.3001 (0.707 sec/step)\n",
            "I0718 09:23:32.967623 140280725968768 learning.py:507] global step 957: loss = 2.1368 (0.661 sec/step)\n",
            "I0718 09:23:33.676166 140280725968768 learning.py:507] global step 958: loss = 3.6520 (0.707 sec/step)\n",
            "I0718 09:23:34.353177 140280725968768 learning.py:507] global step 959: loss = 2.4051 (0.675 sec/step)\n",
            "I0718 09:23:35.029449 140280725968768 learning.py:507] global step 960: loss = 1.7673 (0.674 sec/step)\n",
            "I0718 09:23:35.711966 140280725968768 learning.py:507] global step 961: loss = 2.8458 (0.681 sec/step)\n",
            "I0718 09:23:36.394710 140280725968768 learning.py:507] global step 962: loss = 2.8916 (0.680 sec/step)\n",
            "I0718 09:23:37.065222 140280725968768 learning.py:507] global step 963: loss = 2.3509 (0.668 sec/step)\n",
            "I0718 09:23:37.741796 140280725968768 learning.py:507] global step 964: loss = 2.1746 (0.674 sec/step)\n",
            "I0718 09:23:38.421843 140280725968768 learning.py:507] global step 965: loss = 1.5442 (0.678 sec/step)\n",
            "I0718 09:23:39.114132 140280725968768 learning.py:507] global step 966: loss = 3.0447 (0.691 sec/step)\n",
            "I0718 09:23:39.808582 140280725968768 learning.py:507] global step 967: loss = 2.2976 (0.693 sec/step)\n",
            "I0718 09:23:40.482941 140280725968768 learning.py:507] global step 968: loss = 2.0500 (0.673 sec/step)\n",
            "I0718 09:23:41.159540 140280725968768 learning.py:507] global step 969: loss = 2.2496 (0.675 sec/step)\n",
            "I0718 09:23:41.845577 140280725968768 learning.py:507] global step 970: loss = 3.3026 (0.684 sec/step)\n",
            "I0718 09:23:42.538725 140280725968768 learning.py:507] global step 971: loss = 2.2099 (0.691 sec/step)\n",
            "I0718 09:23:43.229605 140280725968768 learning.py:507] global step 972: loss = 3.0144 (0.689 sec/step)\n",
            "I0718 09:23:43.920699 140280725968768 learning.py:507] global step 973: loss = 2.5443 (0.689 sec/step)\n",
            "I0718 09:23:44.573886 140280725968768 learning.py:507] global step 974: loss = 2.2874 (0.651 sec/step)\n",
            "I0718 09:23:45.291777 140280725968768 learning.py:507] global step 975: loss = 2.2249 (0.716 sec/step)\n",
            "I0718 09:23:45.972786 140280725968768 learning.py:507] global step 976: loss = 3.0086 (0.679 sec/step)\n",
            "I0718 09:23:46.661746 140280725968768 learning.py:507] global step 977: loss = 2.5031 (0.687 sec/step)\n",
            "I0718 09:23:47.348531 140280725968768 learning.py:507] global step 978: loss = 2.5133 (0.685 sec/step)\n",
            "I0718 09:23:48.016746 140280725968768 learning.py:507] global step 979: loss = 1.9598 (0.666 sec/step)\n",
            "I0718 09:23:48.696756 140280725968768 learning.py:507] global step 980: loss = 2.6266 (0.678 sec/step)\n",
            "I0718 09:23:49.368482 140280725968768 learning.py:507] global step 981: loss = 2.8703 (0.670 sec/step)\n",
            "I0718 09:23:50.032778 140280725968768 learning.py:507] global step 982: loss = 2.3146 (0.662 sec/step)\n",
            "I0718 09:23:50.705815 140280725968768 learning.py:507] global step 983: loss = 2.4008 (0.671 sec/step)\n",
            "I0718 09:23:51.405745 140280725968768 learning.py:507] global step 984: loss = 2.6688 (0.698 sec/step)\n",
            "I0718 09:23:52.053018 140280725968768 learning.py:507] global step 985: loss = 1.9790 (0.646 sec/step)\n",
            "I0718 09:23:52.727774 140280725968768 learning.py:507] global step 986: loss = 2.7193 (0.672 sec/step)\n",
            "I0718 09:23:53.416620 140280725968768 learning.py:507] global step 987: loss = 2.3749 (0.687 sec/step)\n",
            "I0718 09:23:54.095089 140280725968768 learning.py:507] global step 988: loss = 2.5947 (0.677 sec/step)\n",
            "I0718 09:23:54.794106 140280725968768 learning.py:507] global step 989: loss = 2.7749 (0.697 sec/step)\n",
            "I0718 09:23:55.470653 140280725968768 learning.py:507] global step 990: loss = 2.3234 (0.675 sec/step)\n",
            "I0718 09:23:56.151541 140280725968768 learning.py:507] global step 991: loss = 1.9665 (0.679 sec/step)\n",
            "I0718 09:23:56.831777 140280725968768 learning.py:507] global step 992: loss = 2.5541 (0.678 sec/step)\n",
            "I0718 09:23:57.537476 140280725968768 learning.py:507] global step 993: loss = 2.0085 (0.704 sec/step)\n",
            "I0718 09:23:58.223383 140280725968768 learning.py:507] global step 994: loss = 1.6816 (0.684 sec/step)\n",
            "I0718 09:23:58.904009 140280725968768 learning.py:507] global step 995: loss = 2.3722 (0.679 sec/step)\n",
            "I0718 09:23:59.589266 140280725968768 learning.py:507] global step 996: loss = 2.6062 (0.683 sec/step)\n",
            "I0718 09:24:00.267016 140280725968768 learning.py:507] global step 997: loss = 2.9465 (0.676 sec/step)\n",
            "I0718 09:24:00.928750 140280725968768 learning.py:507] global step 998: loss = 2.6537 (0.660 sec/step)\n",
            "I0718 09:24:01.596835 140280725968768 learning.py:507] global step 999: loss = 2.9576 (0.666 sec/step)\n",
            "I0718 09:24:02.255579 140280725968768 learning.py:507] global step 1000: loss = 2.8458 (0.657 sec/step)\n",
            "I0718 09:24:02.926275 140280725968768 learning.py:507] global step 1001: loss = 2.7443 (0.669 sec/step)\n",
            "I0718 09:24:03.607119 140280725968768 learning.py:507] global step 1002: loss = 3.4938 (0.679 sec/step)\n",
            "I0718 09:24:04.282222 140280725968768 learning.py:507] global step 1003: loss = 2.5367 (0.673 sec/step)\n",
            "I0718 09:24:04.980633 140280725968768 learning.py:507] global step 1004: loss = 1.9148 (0.696 sec/step)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}